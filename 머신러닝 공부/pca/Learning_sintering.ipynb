{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import initializers, optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy import io\n",
    "df = pd.read_excel(r'0528_transient sintering_measurement dataset.xlsx', sheet_name='Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          총전류       60V      120V       임팩터\n",
      "0     128.750  0.605437  0.221553  0.421553\n",
      "1     128.425  0.606969  0.218221  0.424178\n",
      "2     128.525  0.597160  0.222525  0.422875\n",
      "3     126.200  0.619849  0.233162  0.422544\n",
      "4     127.500  0.612941  0.229020  0.419020\n",
      "...       ...       ...       ...       ...\n",
      "1032   26.325  0.304609  0.606555  0.698955\n",
      "1033   75.075  0.269292  0.572012  0.731269\n",
      "1034   46.025  0.246797  0.521420  0.754481\n",
      "1035   76.600  0.204238  0.436828  0.806462\n",
      "1036   41.375  0.190289  0.470633  0.833435\n",
      "\n",
      "[1037 rows x 4 columns]\n",
      "      전기이동도 입경    공기역학적 입경        밀도\n",
      "0     49.53900  119.452408  2.930149\n",
      "1     49.53900  120.019480  2.948605\n",
      "2     49.12420  117.697687  2.900967\n",
      "3     49.70700  117.541881  2.857277\n",
      "4     49.70700  119.605159  2.923820\n",
      "...        ...         ...       ...\n",
      "1032  44.34600  229.625781  8.128449\n",
      "1033  49.58300  248.953904  8.235648\n",
      "1034  53.50200  262.992716  8.236264\n",
      "1035  70.12925  319.511938  7.544239\n",
      "1036  75.99200  338.552021  9.540853\n",
      "\n",
      "[1037 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(df, columns = ['총전류', '60V','120V','임팩터'])\n",
    "Y = pd.DataFrame(df, columns = ['전기이동도 입경','공기역학적 입경','밀도'])\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128.75         0.60543689   0.2215534    0.4215534 ]\n",
      " [128.425        0.60696905   0.21822075   0.42417754]\n",
      " [128.525        0.59716009   0.2225248    0.42287493]\n",
      " ...\n",
      " [ 46.025        0.24679661   0.52142042   0.75448126]\n",
      " [ 76.6          0.20423766   0.43682831   0.80646214]\n",
      " [ 41.375        0.19028871   0.47063335   0.83343465]]\n",
      "[[ 49.539      119.45240755   2.93014888]\n",
      " [ 49.539      120.01947995   2.94860476]\n",
      " [ 49.1242     117.69768729   2.9009673 ]\n",
      " ...\n",
      " [ 53.502      262.9927164    8.23626382]\n",
      " [ 70.12925    319.51193834   7.54423931]\n",
      " [ 75.992      338.55202081   9.54085338]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "\n",
    "Y=np.array(Y)\n",
    "#Y[:,0] /= 1000\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size =0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00149402 -0.3544815   1.12663252  0.63047703]\n",
      " [-0.09561753  0.33900861 -0.29874142  0.16121262]\n",
      " [ 7.18675299 -0.86627043  0.09831111 -0.51772003]\n",
      " ...\n",
      " [-0.6937251   0.28278516 -0.35754246  0.12864869]\n",
      " [-0.55229084  0.52825089 -0.14077438 -0.1281747 ]\n",
      " [-0.40338645 -0.92468421  0.09197288  0.00995774]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X_train)\n",
    "x_robust_scaled = robust_scaler.transform(X_train)\n",
    "print(x_robust_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.84500894 -0.0830151   1.09038598]\n",
      " [-0.95990989 -0.6822626  -0.39960801]\n",
      " [ 6.37257748 -1.21901811  0.56944856]\n",
      " ...\n",
      " [-1.53791966 -0.56331168 -0.4301486 ]\n",
      " [-1.35159122 -0.29084986 -0.57632283]\n",
      " [-1.15154098 -0.16784182  0.60128362]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#for i in range(n):\n",
    "#    X_ = x_robust_scaled + Y_train[:,i]\n",
    "#    pca = PCA(n_components = 3)\n",
    "#    pca.fit(X_)\n",
    "#    printcipalcomponents = pca.fit_transform(X_)\n",
    "#    pca1.append(principalcomponents, axis=1)\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(x_robust_scaled)\n",
    "principalComponents = pca.fit_transform(x_robust_scaled)\n",
    "x_robust_scaled = principalComponents\n",
    "#x_robust_scaled = np.concatenate((x_robust_scaled, principalComponents), axis=1)\n",
    "print(x_robust_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "#wandb.init(config=tf.flags.FLAGS, sync_tensorboard=True)\n",
    "\n",
    "adam = optimizers.Nadam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon= 0.0001, name=\"Nadam\" )\n",
    "\n",
    "# kernel_initializer=he_normal(), kernel_regularizer = L1L2(l1=0.01, l2=0.01)\n",
    "    #input_layer = Input(shape=(4,), name='input1')\n",
    "    #hidden_layer = Dense(30, activation='relu',weights=(w,b))\n",
    "\n",
    "def mlp_model(input_index, output_index):\n",
    "    model=Sequential([\n",
    "    Dense(100, input_shape=(input_index,)), \n",
    "    Dense(60, activation='relu'),    \n",
    "    Dense(80, activation='relu'),    \n",
    "    Dense(80, activation='relu'),   \n",
    "    Dense(50, activation='relu'),    \n",
    "    Dense(60, activation='relu'),    \n",
    "    Dense(30, activation='relu'),    \n",
    "    Dense(10, activation = 'relu'),\n",
    "    Dense(output_index)])\n",
    "    model.compile(optimizer=adam, loss='mean_squared_error',metrics=[Real_acc])\n",
    "    return model\n",
    "\n",
    "def lstm_mlp_model(input_index, output_index):\n",
    "    model1=Sequential([\n",
    "         Bidirectional(LSTM(60, input_shape = (1,3), return_sequences=True)),\n",
    "         Bidirectional(LSTM(80,return_sequences=True)),\n",
    "         Bidirectional(LSTM(100)),\n",
    "         Dense(70, activation='relu', kernel_regularizer = L1L2(l1=0.01, l2=0.01)),\n",
    "         Dense(60, activation='relu', kernel_regularizer = L1L2(l1=0.01, l2=0.01)),         \n",
    "         Dense(40, activation='relu', kernel_regularizer = L1L2(l1=0.01, l2=0.01)),\n",
    "         Dense(output_index)])\n",
    "    model1.compile(optimizer=adam, loss='mean_squared_error',metrics=[Real_acc])\n",
    "    return model1\n",
    "\n",
    "\n",
    "def Real_acc(y_true,y_pred):\n",
    "    real_accuracy=(abs((y_true)-(y_pred))/(y_true))*100\n",
    "    return real_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933\n"
     ]
    }
   ],
   "source": [
    "x_robust_scaled = x_robust_scaled.reshape((int(len(x_robust_scaled)),1,3))\n",
    "m1,_,n1= x_robust_scaled.shape\n",
    "m2,n2= Y_train.shape\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1,n1= x_robust_scaled.shape\n",
    "m2,n2= Y_train.shape\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "model = lstm_mlp_model(n1,n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0626 18:13:53.049902  2284 base_layer.py:2068] Layer bidirectional is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 13320.2900 - Real_acc: 98.9962 - val_loss: 12321.3506 - val_Real_acc: 94.0480\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7899.6538 - Real_acc: 144.5869 - val_loss: 2906.7925 - val_Real_acc: 161.0961\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 2557.8811 - Real_acc: 92.9987 - val_loss: 2604.7102 - val_Real_acc: 56.2267\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 2345.6501 - Real_acc: 57.3344 - val_loss: 2451.1448 - val_Real_acc: 52.0112\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 2181.4333 - Real_acc: 54.9790 - val_loss: 2300.2227 - val_Real_acc: 54.0149\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 2028.4584 - Real_acc: 57.0465 - val_loss: 2121.0984 - val_Real_acc: 57.3933\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1850.1127 - Real_acc: 61.5151 - val_loss: 1889.3621 - val_Real_acc: 63.1938\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1696.7035 - Real_acc: 65.4972 - val_loss: 1619.4438 - val_Real_acc: 65.9874\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1590.1935 - Real_acc: 67.5398 - val_loss: 1470.9203 - val_Real_acc: 63.8359\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1522.0774 - Real_acc: 64.7180 - val_loss: 1388.3668 - val_Real_acc: 59.4801\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1470.0864 - Real_acc: 60.0040 - val_loss: 1294.1611 - val_Real_acc: 53.8181\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1417.6733 - Real_acc: 56.5305 - val_loss: 1221.4734 - val_Real_acc: 52.1309\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1359.2394 - Real_acc: 54.0365 - val_loss: 1146.0259 - val_Real_acc: 48.3025\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1303.5988 - Real_acc: 53.3445 - val_loss: 1083.7539 - val_Real_acc: 48.3140\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1251.9540 - Real_acc: 53.6776 - val_loss: 998.2091 - val_Real_acc: 47.0521\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1199.3723 - Real_acc: 53.7236 - val_loss: 934.0473 - val_Real_acc: 47.6313\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1141.5262 - Real_acc: 53.4553 - val_loss: 876.7837 - val_Real_acc: 48.9144\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1070.9948 - Real_acc: 54.0238 - val_loss: 775.0457 - val_Real_acc: 47.6960\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1000.3146 - Real_acc: 53.1786 - val_loss: 730.6531 - val_Real_acc: 48.0868\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 942.8485 - Real_acc: 53.3012 - val_loss: 685.2672 - val_Real_acc: 46.8879\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 902.6784 - Real_acc: 52.2202 - val_loss: 675.1616 - val_Real_acc: 48.9817\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 874.2307 - Real_acc: 53.6608 - val_loss: 639.5008 - val_Real_acc: 46.7631\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 858.7874 - Real_acc: 52.3759 - val_loss: 630.3333 - val_Real_acc: 44.9353\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 846.1761 - Real_acc: 52.2237 - val_loss: 631.7383 - val_Real_acc: 46.3808\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 843.3522 - Real_acc: 52.7770 - val_loss: 620.8269 - val_Real_acc: 45.2962\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 832.0149 - Real_acc: 52.1296 - val_loss: 625.3303 - val_Real_acc: 45.9520\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 826.6335 - Real_acc: 52.3639 - val_loss: 617.1146 - val_Real_acc: 46.9788\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 823.9764 - Real_acc: 52.6616 - val_loss: 611.3457 - val_Real_acc: 45.0986\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 820.6593 - Real_acc: 52.0576 - val_loss: 618.6439 - val_Real_acc: 45.8276\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 818.9485 - Real_acc: 52.6095 - val_loss: 612.3375 - val_Real_acc: 45.7840\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 817.9183 - Real_acc: 52.2435 - val_loss: 621.6631 - val_Real_acc: 46.7865\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 815.4163 - Real_acc: 53.2924 - val_loss: 608.1991 - val_Real_acc: 46.7928\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 814.9371 - Real_acc: 52.3760 - val_loss: 615.4994 - val_Real_acc: 46.4504\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 817.2788 - Real_acc: 52.7719 - val_loss: 610.2759 - val_Real_acc: 44.5284\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 818.2065 - Real_acc: 52.0851 - val_loss: 615.0181 - val_Real_acc: 46.3320\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 812.8841 - Real_acc: 52.8003 - val_loss: 608.8724 - val_Real_acc: 46.4026\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 810.7646 - Real_acc: 52.2241 - val_loss: 609.5099 - val_Real_acc: 45.9148\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 808.6658 - Real_acc: 52.8145 - val_loss: 607.1490 - val_Real_acc: 44.7152\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 811.9241 - Real_acc: 52.2910 - val_loss: 602.4175 - val_Real_acc: 45.5562\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 807.5425 - Real_acc: 51.9178 - val_loss: 607.8354 - val_Real_acc: 46.5503\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 806.3716 - Real_acc: 52.3495 - val_loss: 607.0427 - val_Real_acc: 46.6152\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 803.3628 - Real_acc: 52.2027 - val_loss: 608.3868 - val_Real_acc: 45.7790\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 801.2382 - Real_acc: 52.3804 - val_loss: 602.9447 - val_Real_acc: 46.5445\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 798.0488 - Real_acc: 52.5159 - val_loss: 592.3474 - val_Real_acc: 46.4878\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 795.8309 - Real_acc: 51.9239 - val_loss: 594.3159 - val_Real_acc: 45.3197\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 790.6010 - Real_acc: 52.0898 - val_loss: 589.4385 - val_Real_acc: 45.2849\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 789.0908 - Real_acc: 51.8491 - val_loss: 582.5977 - val_Real_acc: 46.0412\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 774.4351 - Real_acc: 51.6384 - val_loss: 582.2412 - val_Real_acc: 45.7423\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 761.7068 - Real_acc: 52.9161 - val_loss: 564.1750 - val_Real_acc: 46.5983\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 747.4626 - Real_acc: 52.2985 - val_loss: 551.9089 - val_Real_acc: 46.1753\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 718.6608 - Real_acc: 52.8302 - val_loss: 529.3786 - val_Real_acc: 45.3298\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 681.2619 - Real_acc: 52.8914 - val_loss: 503.4644 - val_Real_acc: 45.0905\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 630.7595 - Real_acc: 52.7363 - val_loss: 469.3886 - val_Real_acc: 45.8128\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 569.6395 - Real_acc: 52.7515 - val_loss: 424.1001 - val_Real_acc: 43.4687\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 500.8059 - Real_acc: 50.3960 - val_loss: 383.9667 - val_Real_acc: 43.2728\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 435.0935 - Real_acc: 46.9806 - val_loss: 345.8547 - val_Real_acc: 40.7762\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 378.5192 - Real_acc: 40.7780 - val_loss: 308.0115 - val_Real_acc: 36.4641\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 333.9588 - Real_acc: 34.6533 - val_loss: 280.9286 - val_Real_acc: 29.6349\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 303.5322 - Real_acc: 30.4482 - val_loss: 260.8450 - val_Real_acc: 25.1420\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 286.0856 - Real_acc: 28.8870 - val_loss: 246.4318 - val_Real_acc: 25.5458\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 271.0973 - Real_acc: 28.7105 - val_loss: 243.4135 - val_Real_acc: 23.8963\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 261.6882 - Real_acc: 27.7031 - val_loss: 238.0795 - val_Real_acc: 25.2681\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 255.0607 - Real_acc: 27.8768 - val_loss: 225.5793 - val_Real_acc: 23.5805\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 253.6225 - Real_acc: 26.8826 - val_loss: 222.7588 - val_Real_acc: 23.7524\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 244.5413 - Real_acc: 26.8431 - val_loss: 223.6658 - val_Real_acc: 24.4437\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 240.8349 - Real_acc: 26.8685 - val_loss: 217.5265 - val_Real_acc: 22.0619\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 236.8394 - Real_acc: 26.0280 - val_loss: 215.6650 - val_Real_acc: 21.7645\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 232.6695 - Real_acc: 25.7263 - val_loss: 211.6993 - val_Real_acc: 22.8393\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 230.7160 - Real_acc: 25.7847 - val_loss: 206.9941 - val_Real_acc: 21.6248\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 228.4694 - Real_acc: 25.2736 - val_loss: 204.8163 - val_Real_acc: 22.0142\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 225.7447 - Real_acc: 25.1311 - val_loss: 208.9368 - val_Real_acc: 22.7987\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 222.3859 - Real_acc: 25.1342 - val_loss: 200.7555 - val_Real_acc: 21.5024\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 221.3520 - Real_acc: 25.1420 - val_loss: 199.0900 - val_Real_acc: 20.7991\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 218.5686 - Real_acc: 24.6047 - val_loss: 199.9524 - val_Real_acc: 22.1944\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 217.6545 - Real_acc: 24.5467 - val_loss: 204.4007 - val_Real_acc: 22.4063\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 214.8180 - Real_acc: 24.7795 - val_loss: 197.0027 - val_Real_acc: 20.4257\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 214.9104 - Real_acc: 23.9964 - val_loss: 193.2349 - val_Real_acc: 21.7799\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 212.2493 - Real_acc: 23.9920 - val_loss: 197.7173 - val_Real_acc: 22.2836\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 212.6243 - Real_acc: 24.5463 - val_loss: 190.3745 - val_Real_acc: 20.1741\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 210.1917 - Real_acc: 23.6977 - val_loss: 188.3170 - val_Real_acc: 21.1738\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 207.9804 - Real_acc: 23.6576 - val_loss: 191.2384 - val_Real_acc: 21.1985\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 207.3796 - Real_acc: 24.1939 - val_loss: 188.6140 - val_Real_acc: 20.2565\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 205.8425 - Real_acc: 23.9994 - val_loss: 189.2491 - val_Real_acc: 20.5145\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 204.8924 - Real_acc: 23.6248 - val_loss: 187.1198 - val_Real_acc: 20.8912\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 204.4375 - Real_acc: 23.8247 - val_loss: 185.2407 - val_Real_acc: 22.8739\n",
      "Epoch 86/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 200.6653 - Real_acc: 23.8864 - val_loss: 189.2812 - val_Real_acc: 22.1758\n",
      "Epoch 87/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 200.7841 - Real_acc: 23.7484 - val_loss: 182.1798 - val_Real_acc: 21.4495\n",
      "Epoch 88/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 199.1278 - Real_acc: 23.8756 - val_loss: 186.1939 - val_Real_acc: 22.7543\n",
      "Epoch 89/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 199.3452 - Real_acc: 23.8884 - val_loss: 180.1585 - val_Real_acc: 20.3965\n",
      "Epoch 90/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 198.1373 - Real_acc: 23.6515 - val_loss: 179.9528 - val_Real_acc: 20.7243\n",
      "Epoch 91/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 197.5174 - Real_acc: 23.6435 - val_loss: 178.3400 - val_Real_acc: 20.3212\n",
      "Epoch 92/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 193.9129 - Real_acc: 23.5963 - val_loss: 185.3647 - val_Real_acc: 23.0613\n",
      "Epoch 93/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 196.3552 - Real_acc: 24.0253 - val_loss: 177.4319 - val_Real_acc: 20.0068\n",
      "Epoch 94/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 193.0113 - Real_acc: 23.7975 - val_loss: 175.7260 - val_Real_acc: 20.7727\n",
      "Epoch 95/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 191.3895 - Real_acc: 23.4135 - val_loss: 173.4990 - val_Real_acc: 20.7892\n",
      "Epoch 96/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 190.9436 - Real_acc: 23.3358 - val_loss: 173.9884 - val_Real_acc: 20.4755\n",
      "Epoch 97/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 190.1998 - Real_acc: 23.6116 - val_loss: 174.8975 - val_Real_acc: 20.8010\n",
      "Epoch 98/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 189.1880 - Real_acc: 23.2927 - val_loss: 177.1352 - val_Real_acc: 21.4904\n",
      "Epoch 99/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 190.1062 - Real_acc: 23.6587 - val_loss: 171.8152 - val_Real_acc: 20.7725\n",
      "Epoch 100/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 186.3310 - Real_acc: 23.5120 - val_loss: 169.7755 - val_Real_acc: 21.3952\n",
      "Epoch 101/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 184.8725 - Real_acc: 23.2536 - val_loss: 173.0964 - val_Real_acc: 21.6702\n",
      "Epoch 102/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 184.4222 - Real_acc: 23.2762 - val_loss: 167.5203 - val_Real_acc: 21.0489\n",
      "Epoch 103/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 182.9528 - Real_acc: 23.4059 - val_loss: 166.9302 - val_Real_acc: 20.1731\n",
      "Epoch 104/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 181.4793 - Real_acc: 23.5105 - val_loss: 170.1798 - val_Real_acc: 21.5241\n",
      "Epoch 105/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 182.1549 - Real_acc: 23.4559 - val_loss: 170.7082 - val_Real_acc: 22.0222\n",
      "Epoch 106/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 181.5279 - Real_acc: 23.2740 - val_loss: 165.3956 - val_Real_acc: 20.6958\n",
      "Epoch 107/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 178.4663 - Real_acc: 23.4998 - val_loss: 163.9918 - val_Real_acc: 21.3309\n",
      "Epoch 108/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 176.9062 - Real_acc: 23.2953 - val_loss: 168.3320 - val_Real_acc: 21.9490\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 177.4912 - Real_acc: 23.3440 - val_loss: 162.3959 - val_Real_acc: 20.3549\n",
      "Epoch 110/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 173.1348 - Real_acc: 23.0673 - val_loss: 162.6492 - val_Real_acc: 19.4515\n",
      "Epoch 111/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 174.5024 - Real_acc: 23.3056 - val_loss: 158.4161 - val_Real_acc: 21.9154\n",
      "Epoch 112/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 171.9685 - Real_acc: 22.6730 - val_loss: 157.7689 - val_Real_acc: 19.7191\n",
      "Epoch 113/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 170.4974 - Real_acc: 22.3896 - val_loss: 157.1428 - val_Real_acc: 21.0527\n",
      "Epoch 114/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 166.1525 - Real_acc: 22.8429 - val_loss: 165.9743 - val_Real_acc: 21.6685\n",
      "Epoch 115/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 167.2667 - Real_acc: 22.3633 - val_loss: 152.2825 - val_Real_acc: 19.1627\n",
      "Epoch 116/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 165.1814 - Real_acc: 22.1412 - val_loss: 151.4303 - val_Real_acc: 19.5045\n",
      "Epoch 117/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 163.0779 - Real_acc: 22.2234 - val_loss: 149.7920 - val_Real_acc: 19.2710\n",
      "Epoch 118/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 161.7478 - Real_acc: 21.9215 - val_loss: 151.6467 - val_Real_acc: 19.4867\n",
      "Epoch 119/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 160.2183 - Real_acc: 21.9452 - val_loss: 147.4908 - val_Real_acc: 19.3144\n",
      "Epoch 120/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 159.4568 - Real_acc: 22.1223 - val_loss: 145.7247 - val_Real_acc: 19.2706\n",
      "Epoch 121/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 155.1413 - Real_acc: 21.3568 - val_loss: 142.9027 - val_Real_acc: 18.9052\n",
      "Epoch 122/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 153.1430 - Real_acc: 21.2104 - val_loss: 142.2617 - val_Real_acc: 19.3534\n",
      "Epoch 123/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 150.5434 - Real_acc: 21.0703 - val_loss: 139.5874 - val_Real_acc: 18.3899\n",
      "Epoch 124/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 147.8281 - Real_acc: 20.6380 - val_loss: 136.3949 - val_Real_acc: 19.3516\n",
      "Epoch 125/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 144.0498 - Real_acc: 20.7892 - val_loss: 142.5233 - val_Real_acc: 19.8230\n",
      "Epoch 126/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 141.7620 - Real_acc: 20.5731 - val_loss: 131.8062 - val_Real_acc: 17.8546\n",
      "Epoch 127/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 139.8879 - Real_acc: 20.6087 - val_loss: 131.5147 - val_Real_acc: 18.0713\n",
      "Epoch 128/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 135.5110 - Real_acc: 20.2339 - val_loss: 139.5140 - val_Real_acc: 19.9701\n",
      "Epoch 129/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 132.4295 - Real_acc: 19.8447 - val_loss: 123.2679 - val_Real_acc: 17.5752\n",
      "Epoch 130/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 128.5637 - Real_acc: 19.6339 - val_loss: 123.0632 - val_Real_acc: 17.9649\n",
      "Epoch 131/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 125.4089 - Real_acc: 19.8649 - val_loss: 122.2083 - val_Real_acc: 17.9850\n",
      "Epoch 132/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 121.5140 - Real_acc: 19.4736 - val_loss: 117.5725 - val_Real_acc: 17.5867\n",
      "Epoch 133/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 119.7964 - Real_acc: 19.1940 - val_loss: 113.6529 - val_Real_acc: 17.3130\n",
      "Epoch 134/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 114.0131 - Real_acc: 18.6952 - val_loss: 108.1920 - val_Real_acc: 17.0341\n",
      "Epoch 135/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 110.4424 - Real_acc: 18.1378 - val_loss: 117.5739 - val_Real_acc: 18.1170\n",
      "Epoch 136/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 106.6072 - Real_acc: 17.9900 - val_loss: 108.5030 - val_Real_acc: 17.5669\n",
      "Epoch 137/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 103.2457 - Real_acc: 17.5662 - val_loss: 104.3531 - val_Real_acc: 16.6679\n",
      "Epoch 138/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 98.4180 - Real_acc: 17.3513 - val_loss: 96.3472 - val_Real_acc: 15.7979\n",
      "Epoch 139/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 94.9727 - Real_acc: 17.0431 - val_loss: 98.0646 - val_Real_acc: 16.3595\n",
      "Epoch 140/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 92.3558 - Real_acc: 16.3657 - val_loss: 92.4189 - val_Real_acc: 15.3813\n",
      "Epoch 141/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 87.7201 - Real_acc: 15.9897 - val_loss: 90.1680 - val_Real_acc: 15.1252\n",
      "Epoch 142/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 84.9011 - Real_acc: 15.6998 - val_loss: 87.0815 - val_Real_acc: 15.0575\n",
      "Epoch 143/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 82.9386 - Real_acc: 15.2060 - val_loss: 95.0904 - val_Real_acc: 15.9761\n",
      "Epoch 144/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 80.7065 - Real_acc: 14.8090 - val_loss: 87.7675 - val_Real_acc: 15.0512\n",
      "Epoch 145/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 79.3175 - Real_acc: 14.5222 - val_loss: 111.0727 - val_Real_acc: 17.5390\n",
      "Epoch 146/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 78.8805 - Real_acc: 14.4777 - val_loss: 90.4012 - val_Real_acc: 16.8927\n",
      "Epoch 147/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 74.5164 - Real_acc: 13.9214 - val_loss: 86.6684 - val_Real_acc: 15.2178\n",
      "Epoch 148/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 72.0804 - Real_acc: 13.7844 - val_loss: 78.3705 - val_Real_acc: 14.1397\n",
      "Epoch 149/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 71.6194 - Real_acc: 13.4388 - val_loss: 74.8141 - val_Real_acc: 14.1069\n",
      "Epoch 150/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 70.4090 - Real_acc: 13.4002 - val_loss: 73.5646 - val_Real_acc: 13.8161\n",
      "Epoch 151/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 68.2701 - Real_acc: 13.1369 - val_loss: 73.9357 - val_Real_acc: 13.6312\n",
      "Epoch 152/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 66.3506 - Real_acc: 12.9503 - val_loss: 74.8989 - val_Real_acc: 14.2333\n",
      "Epoch 153/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 64.7413 - Real_acc: 12.9141 - val_loss: 70.4323 - val_Real_acc: 13.3330\n",
      "Epoch 154/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 65.6910 - Real_acc: 12.6327 - val_loss: 71.2106 - val_Real_acc: 13.9580\n",
      "Epoch 155/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 63.0964 - Real_acc: 12.6825 - val_loss: 70.2369 - val_Real_acc: 13.1809\n",
      "Epoch 156/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 62.0334 - Real_acc: 12.6409 - val_loss: 67.8202 - val_Real_acc: 12.7473\n",
      "Epoch 157/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 61.1641 - Real_acc: 12.4915 - val_loss: 75.9506 - val_Real_acc: 14.7022\n",
      "Epoch 158/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 60.3488 - Real_acc: 12.2145 - val_loss: 69.0011 - val_Real_acc: 13.3646\n",
      "Epoch 159/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 59.3936 - Real_acc: 12.2432 - val_loss: 65.3806 - val_Real_acc: 12.6310\n",
      "Epoch 160/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 58.7012 - Real_acc: 12.4040 - val_loss: 74.6556 - val_Real_acc: 13.9010\n",
      "Epoch 161/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 57.5143 - Real_acc: 12.4064 - val_loss: 64.4377 - val_Real_acc: 12.7125\n",
      "Epoch 162/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 56.0916 - Real_acc: 12.1784 - val_loss: 67.4787 - val_Real_acc: 12.9254\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 54.4879 - Real_acc: 12.5141 - val_loss: 65.4843 - val_Real_acc: 12.8707\n",
      "Epoch 164/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 53.9526 - Real_acc: 12.4090 - val_loss: 62.1025 - val_Real_acc: 12.7266\n",
      "Epoch 165/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 53.7499 - Real_acc: 12.1663 - val_loss: 64.6615 - val_Real_acc: 12.6492\n",
      "Epoch 166/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 52.6367 - Real_acc: 12.0943 - val_loss: 61.1969 - val_Real_acc: 12.6688\n",
      "Epoch 167/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 52.2969 - Real_acc: 11.9274 - val_loss: 63.8717 - val_Real_acc: 12.9981\n",
      "Epoch 168/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 51.3786 - Real_acc: 12.1727 - val_loss: 63.9276 - val_Real_acc: 13.0136\n",
      "Epoch 169/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 50.2658 - Real_acc: 11.8902 - val_loss: 62.2383 - val_Real_acc: 12.7115\n",
      "Epoch 170/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 49.9401 - Real_acc: 11.7795 - val_loss: 59.8696 - val_Real_acc: 12.9718\n",
      "Epoch 171/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 48.4714 - Real_acc: 12.0267 - val_loss: 61.1063 - val_Real_acc: 12.9570\n",
      "Epoch 172/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 47.1367 - Real_acc: 11.9156 - val_loss: 59.0504 - val_Real_acc: 12.6754\n",
      "Epoch 173/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 47.7985 - Real_acc: 11.7469 - val_loss: 59.7406 - val_Real_acc: 12.5062\n",
      "Epoch 174/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 46.0999 - Real_acc: 11.4796 - val_loss: 56.1124 - val_Real_acc: 11.9986\n",
      "Epoch 175/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 45.9626 - Real_acc: 11.4499 - val_loss: 59.9539 - val_Real_acc: 12.1395\n",
      "Epoch 176/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 44.7275 - Real_acc: 11.4527 - val_loss: 56.1910 - val_Real_acc: 12.0986\n",
      "Epoch 177/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 44.0035 - Real_acc: 11.2192 - val_loss: 54.9848 - val_Real_acc: 12.6411\n",
      "Epoch 178/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 42.7679 - Real_acc: 11.4590 - val_loss: 54.6897 - val_Real_acc: 12.3849\n",
      "Epoch 179/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 42.8085 - Real_acc: 11.3590 - val_loss: 53.7877 - val_Real_acc: 11.6636\n",
      "Epoch 180/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 41.6910 - Real_acc: 11.1047 - val_loss: 55.8438 - val_Real_acc: 11.7581\n",
      "Epoch 181/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 40.8782 - Real_acc: 10.8127 - val_loss: 53.3130 - val_Real_acc: 12.1264\n",
      "Epoch 182/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 39.5587 - Real_acc: 10.7327 - val_loss: 54.9165 - val_Real_acc: 11.5504\n",
      "Epoch 183/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 39.5935 - Real_acc: 10.7314 - val_loss: 52.4131 - val_Real_acc: 11.4766\n",
      "Epoch 184/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 38.4727 - Real_acc: 10.6057 - val_loss: 53.5944 - val_Real_acc: 12.0307\n",
      "Epoch 185/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 38.5785 - Real_acc: 10.4902 - val_loss: 53.3067 - val_Real_acc: 11.2429\n",
      "Epoch 186/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 37.6022 - Real_acc: 10.2433 - val_loss: 50.9327 - val_Real_acc: 11.2392\n",
      "Epoch 187/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 37.0232 - Real_acc: 10.2319 - val_loss: 51.8771 - val_Real_acc: 11.0872\n",
      "Epoch 188/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 36.1096 - Real_acc: 10.2336 - val_loss: 54.0156 - val_Real_acc: 11.0812\n",
      "Epoch 189/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 35.7420 - Real_acc: 10.0056 - val_loss: 50.4666 - val_Real_acc: 11.0717\n",
      "Epoch 190/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 34.8368 - Real_acc: 10.0562 - val_loss: 47.5585 - val_Real_acc: 11.3243\n",
      "Epoch 191/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 34.2780 - Real_acc: 9.8642 - val_loss: 46.5097 - val_Real_acc: 10.7496\n",
      "Epoch 192/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 34.1690 - Real_acc: 9.4922 - val_loss: 46.3247 - val_Real_acc: 10.8303\n",
      "Epoch 193/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 32.8030 - Real_acc: 9.9462 - val_loss: 45.1694 - val_Real_acc: 10.5288\n",
      "Epoch 194/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 33.2708 - Real_acc: 9.4467 - val_loss: 49.1574 - val_Real_acc: 10.4653\n",
      "Epoch 195/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 32.7340 - Real_acc: 9.2668 - val_loss: 46.7995 - val_Real_acc: 10.0202\n",
      "Epoch 196/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 32.1121 - Real_acc: 9.4823 - val_loss: 45.7439 - val_Real_acc: 10.0118\n",
      "Epoch 197/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 30.9599 - Real_acc: 9.1232 - val_loss: 43.6635 - val_Real_acc: 9.9136\n",
      "Epoch 198/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 30.3886 - Real_acc: 9.0338 - val_loss: 41.2657 - val_Real_acc: 10.5190\n",
      "Epoch 199/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 30.3439 - Real_acc: 8.9621 - val_loss: 40.5738 - val_Real_acc: 9.6239\n",
      "Epoch 200/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 30.4173 - Real_acc: 8.9286 - val_loss: 39.9907 - val_Real_acc: 9.3171\n",
      "Epoch 201/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 29.3797 - Real_acc: 8.4837 - val_loss: 40.5204 - val_Real_acc: 9.2408\n",
      "Epoch 202/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 29.0706 - Real_acc: 8.7152 - val_loss: 39.4686 - val_Real_acc: 9.2217\n",
      "Epoch 203/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 28.7767 - Real_acc: 8.4115 - val_loss: 40.9888 - val_Real_acc: 9.5018\n",
      "Epoch 204/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 28.1805 - Real_acc: 8.2775 - val_loss: 39.2769 - val_Real_acc: 9.5487\n",
      "Epoch 205/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 27.9906 - Real_acc: 8.1742 - val_loss: 37.4683 - val_Real_acc: 9.3181\n",
      "Epoch 206/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 28.1109 - Real_acc: 7.9094 - val_loss: 38.6007 - val_Real_acc: 8.6165\n",
      "Epoch 207/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 27.4467 - Real_acc: 7.7737 - val_loss: 37.8254 - val_Real_acc: 8.6165\n",
      "Epoch 208/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 27.0092 - Real_acc: 7.6303 - val_loss: 36.3643 - val_Real_acc: 8.4780\n",
      "Epoch 209/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 26.8534 - Real_acc: 7.4731 - val_loss: 36.8132 - val_Real_acc: 9.3682\n",
      "Epoch 210/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 26.4055 - Real_acc: 7.3749 - val_loss: 37.2336 - val_Real_acc: 9.1315\n",
      "Epoch 211/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 26.2982 - Real_acc: 7.4882 - val_loss: 36.5058 - val_Real_acc: 8.2262\n",
      "Epoch 212/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 26.1611 - Real_acc: 7.3533 - val_loss: 35.7225 - val_Real_acc: 7.8080\n",
      "Epoch 213/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 25.9419 - Real_acc: 7.0509 - val_loss: 35.8886 - val_Real_acc: 8.4535\n",
      "Epoch 214/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 25.6545 - Real_acc: 7.2943 - val_loss: 35.6866 - val_Real_acc: 7.6908\n",
      "Epoch 215/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 25.3969 - Real_acc: 7.0344 - val_loss: 33.4693 - val_Real_acc: 8.5334\n",
      "Epoch 216/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 25.2207 - Real_acc: 7.2431 - val_loss: 32.7341 - val_Real_acc: 7.4894\n",
      "Epoch 217/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.9738 - Real_acc: 7.4820 - val_loss: 34.1726 - val_Real_acc: 7.7476\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 24.8236 - Real_acc: 7.0408 - val_loss: 33.8219 - val_Real_acc: 8.1078\n",
      "Epoch 219/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.7434 - Real_acc: 7.0515 - val_loss: 32.3608 - val_Real_acc: 7.6442\n",
      "Epoch 220/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.6658 - Real_acc: 7.2581 - val_loss: 32.1169 - val_Real_acc: 8.2310\n",
      "Epoch 221/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.4727 - Real_acc: 7.0867 - val_loss: 32.0877 - val_Real_acc: 7.3554\n",
      "Epoch 222/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.2363 - Real_acc: 6.9232 - val_loss: 32.7128 - val_Real_acc: 7.4954\n",
      "Epoch 223/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.2255 - Real_acc: 7.1951 - val_loss: 31.8490 - val_Real_acc: 7.3977\n",
      "Epoch 224/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.2792 - Real_acc: 6.8102 - val_loss: 31.0812 - val_Real_acc: 7.6226\n",
      "Epoch 225/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 24.0390 - Real_acc: 6.8053 - val_loss: 31.4159 - val_Real_acc: 7.2606\n",
      "Epoch 226/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.9187 - Real_acc: 6.8681 - val_loss: 30.9233 - val_Real_acc: 7.3079\n",
      "Epoch 227/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.7306 - Real_acc: 6.6010 - val_loss: 30.8474 - val_Real_acc: 7.0931\n",
      "Epoch 228/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.6842 - Real_acc: 6.7190 - val_loss: 30.2863 - val_Real_acc: 8.0642\n",
      "Epoch 229/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.3757 - Real_acc: 6.7949 - val_loss: 30.3027 - val_Real_acc: 7.0421\n",
      "Epoch 230/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.3419 - Real_acc: 6.6074 - val_loss: 29.7840 - val_Real_acc: 6.9566\n",
      "Epoch 231/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.2452 - Real_acc: 6.6071 - val_loss: 31.1275 - val_Real_acc: 7.2219\n",
      "Epoch 232/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.8598 - Real_acc: 6.5441 - val_loss: 29.0423 - val_Real_acc: 6.8658\n",
      "Epoch 233/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.8580 - Real_acc: 6.3143 - val_loss: 29.7581 - val_Real_acc: 7.7653\n",
      "Epoch 234/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 23.0741 - Real_acc: 6.7919 - val_loss: 29.2220 - val_Real_acc: 6.9876\n",
      "Epoch 235/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.7239 - Real_acc: 6.5740 - val_loss: 30.2244 - val_Real_acc: 7.5420\n",
      "Epoch 236/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.6468 - Real_acc: 6.5208 - val_loss: 29.0847 - val_Real_acc: 7.2932\n",
      "Epoch 237/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.5172 - Real_acc: 6.5854 - val_loss: 30.0016 - val_Real_acc: 7.4558\n",
      "Epoch 238/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.3206 - Real_acc: 6.7207 - val_loss: 28.2912 - val_Real_acc: 6.9548\n",
      "Epoch 239/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 22.1434 - Real_acc: 6.4732 - val_loss: 29.3977 - val_Real_acc: 7.3614\n",
      "Epoch 240/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.9538 - Real_acc: 6.8986 - val_loss: 28.8175 - val_Real_acc: 8.6770\n",
      "Epoch 241/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.9005 - Real_acc: 6.6954 - val_loss: 28.6281 - val_Real_acc: 7.4183\n",
      "Epoch 242/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.8555 - Real_acc: 6.7477 - val_loss: 28.6054 - val_Real_acc: 7.3097\n",
      "Epoch 243/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.9937 - Real_acc: 6.6894 - val_loss: 27.6483 - val_Real_acc: 6.9046\n",
      "Epoch 244/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.8630 - Real_acc: 6.8882 - val_loss: 27.2558 - val_Real_acc: 7.5253\n",
      "Epoch 245/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.3157 - Real_acc: 6.3117 - val_loss: 27.3615 - val_Real_acc: 6.8877\n",
      "Epoch 246/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.3937 - Real_acc: 6.3353 - val_loss: 27.5844 - val_Real_acc: 7.4156\n",
      "Epoch 247/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.2756 - Real_acc: 6.2906 - val_loss: 28.2733 - val_Real_acc: 7.9682\n",
      "Epoch 248/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.1095 - Real_acc: 6.6538 - val_loss: 27.4743 - val_Real_acc: 7.0981\n",
      "Epoch 249/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.1355 - Real_acc: 6.3420 - val_loss: 27.3633 - val_Real_acc: 6.7017\n",
      "Epoch 250/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 21.3727 - Real_acc: 6.2466 - val_loss: 26.2327 - val_Real_acc: 7.4293\n",
      "Epoch 251/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.9899 - Real_acc: 6.2037 - val_loss: 26.6958 - val_Real_acc: 7.0564\n",
      "Epoch 252/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.8296 - Real_acc: 6.1389 - val_loss: 26.6135 - val_Real_acc: 7.5199\n",
      "Epoch 253/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.6852 - Real_acc: 6.2299 - val_loss: 26.6543 - val_Real_acc: 7.2958\n",
      "Epoch 254/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.6246 - Real_acc: 6.3489 - val_loss: 26.2708 - val_Real_acc: 6.7883\n",
      "Epoch 255/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.5126 - Real_acc: 6.1699 - val_loss: 25.8847 - val_Real_acc: 6.9622\n",
      "Epoch 256/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.3797 - Real_acc: 5.9142 - val_loss: 26.2928 - val_Real_acc: 6.6301\n",
      "Epoch 257/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.3154 - Real_acc: 6.0598 - val_loss: 25.8553 - val_Real_acc: 6.6039\n",
      "Epoch 258/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.2598 - Real_acc: 6.1013 - val_loss: 26.6208 - val_Real_acc: 6.7709\n",
      "Epoch 259/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.4760 - Real_acc: 5.9920 - val_loss: 25.5229 - val_Real_acc: 7.0615\n",
      "Epoch 260/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.8571 - Real_acc: 5.8730 - val_loss: 25.4922 - val_Real_acc: 6.6734\n",
      "Epoch 261/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 20.0097 - Real_acc: 6.0051 - val_loss: 25.5862 - val_Real_acc: 6.9535\n",
      "Epoch 262/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.8591 - Real_acc: 5.9487 - val_loss: 25.3727 - val_Real_acc: 7.0120\n",
      "Epoch 263/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.8841 - Real_acc: 5.9324 - val_loss: 25.2673 - val_Real_acc: 6.8404\n",
      "Epoch 264/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.5560 - Real_acc: 5.8429 - val_loss: 25.3765 - val_Real_acc: 6.5149\n",
      "Epoch 265/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.7624 - Real_acc: 5.9080 - val_loss: 24.8770 - val_Real_acc: 7.1539\n",
      "Epoch 266/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.4167 - Real_acc: 5.9430 - val_loss: 26.8682 - val_Real_acc: 7.0897\n",
      "Epoch 267/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.6290 - Real_acc: 5.8415 - val_loss: 24.5226 - val_Real_acc: 6.4613\n",
      "Epoch 268/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.5905 - Real_acc: 5.7869 - val_loss: 24.0607 - val_Real_acc: 7.2266\n",
      "Epoch 269/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.4170 - Real_acc: 5.7470 - val_loss: 25.3713 - val_Real_acc: 6.7749\n",
      "Epoch 270/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.1689 - Real_acc: 5.6243 - val_loss: 24.4073 - val_Real_acc: 6.9501\n",
      "Epoch 271/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.9976 - Real_acc: 5.7719 - val_loss: 24.2517 - val_Real_acc: 6.9252\n",
      "Epoch 272/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.9579 - Real_acc: 5.6662 - val_loss: 24.7327 - val_Real_acc: 6.4447\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 18.9806 - Real_acc: 5.6160 - val_loss: 23.6397 - val_Real_acc: 6.3164\n",
      "Epoch 274/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.7824 - Real_acc: 5.5634 - val_loss: 23.9019 - val_Real_acc: 6.7510\n",
      "Epoch 275/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.7875 - Real_acc: 5.6483 - val_loss: 23.5934 - val_Real_acc: 6.9540\n",
      "Epoch 276/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.8750 - Real_acc: 5.9524 - val_loss: 23.9106 - val_Real_acc: 7.1161\n",
      "Epoch 277/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.5994 - Real_acc: 5.6812 - val_loss: 23.3799 - val_Real_acc: 6.8404\n",
      "Epoch 278/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.5185 - Real_acc: 5.6883 - val_loss: 23.2785 - val_Real_acc: 6.3716\n",
      "Epoch 279/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.9132 - Real_acc: 5.5796 - val_loss: 23.4805 - val_Real_acc: 7.0165\n",
      "Epoch 280/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.5431 - Real_acc: 5.5984 - val_loss: 23.3073 - val_Real_acc: 6.3948\n",
      "Epoch 281/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.3955 - Real_acc: 5.5528 - val_loss: 23.3374 - val_Real_acc: 6.3951\n",
      "Epoch 282/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.2422 - Real_acc: 5.4086 - val_loss: 23.3245 - val_Real_acc: 6.5799\n",
      "Epoch 283/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.1282 - Real_acc: 5.7538 - val_loss: 23.5743 - val_Real_acc: 6.4712\n",
      "Epoch 284/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.1238 - Real_acc: 5.6068 - val_loss: 22.6985 - val_Real_acc: 6.1857\n",
      "Epoch 285/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.9974 - Real_acc: 5.6294 - val_loss: 22.6189 - val_Real_acc: 6.4746\n",
      "Epoch 286/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.4390 - Real_acc: 5.5353 - val_loss: 23.2083 - val_Real_acc: 7.1634\n",
      "Epoch 287/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.0857 - Real_acc: 5.5046 - val_loss: 22.3013 - val_Real_acc: 6.5197\n",
      "Epoch 288/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.7554 - Real_acc: 5.5212 - val_loss: 21.7915 - val_Real_acc: 6.3206\n",
      "Epoch 289/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.7862 - Real_acc: 5.6510 - val_loss: 21.8822 - val_Real_acc: 6.5410\n",
      "Epoch 290/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.7575 - Real_acc: 5.5324 - val_loss: 21.7097 - val_Real_acc: 6.6543\n",
      "Epoch 291/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.7187 - Real_acc: 5.3883 - val_loss: 22.0800 - val_Real_acc: 6.3728\n",
      "Epoch 292/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.6517 - Real_acc: 5.3826 - val_loss: 21.8102 - val_Real_acc: 6.6295\n",
      "Epoch 293/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.5610 - Real_acc: 5.5489 - val_loss: 21.6411 - val_Real_acc: 6.4546\n",
      "Epoch 294/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.5620 - Real_acc: 5.5269 - val_loss: 22.0490 - val_Real_acc: 7.2553\n",
      "Epoch 295/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.1309 - Real_acc: 5.6638 - val_loss: 21.3327 - val_Real_acc: 7.2841\n",
      "Epoch 296/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.4425 - Real_acc: 5.4953 - val_loss: 20.9347 - val_Real_acc: 6.7975\n",
      "Epoch 297/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.2461 - Real_acc: 5.3883 - val_loss: 21.1733 - val_Real_acc: 7.1513\n",
      "Epoch 298/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.3791 - Real_acc: 5.3917 - val_loss: 20.8157 - val_Real_acc: 6.4670\n",
      "Epoch 299/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.4349 - Real_acc: 5.5081 - val_loss: 21.2632 - val_Real_acc: 6.4592\n",
      "Epoch 300/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.1961 - Real_acc: 5.3912 - val_loss: 20.8144 - val_Real_acc: 6.2361\n",
      "Epoch 301/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.7394 - Real_acc: 5.3857 - val_loss: 20.9698 - val_Real_acc: 6.8447\n",
      "Epoch 302/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.9379 - Real_acc: 5.3926 - val_loss: 20.6053 - val_Real_acc: 6.5860\n",
      "Epoch 303/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.9043 - Real_acc: 5.4069 - val_loss: 20.5863 - val_Real_acc: 6.5707\n",
      "Epoch 304/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.9981 - Real_acc: 5.3432 - val_loss: 20.7086 - val_Real_acc: 6.7310\n",
      "Epoch 305/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.9700 - Real_acc: 5.5563 - val_loss: 20.8134 - val_Real_acc: 6.3159\n",
      "Epoch 306/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.8055 - Real_acc: 5.4971 - val_loss: 20.2998 - val_Real_acc: 6.2707\n",
      "Epoch 307/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.2229 - Real_acc: 5.2292 - val_loss: 20.9242 - val_Real_acc: 6.4950\n",
      "Epoch 308/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.7641 - Real_acc: 5.3619 - val_loss: 20.2076 - val_Real_acc: 6.5203\n",
      "Epoch 309/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.4994 - Real_acc: 5.3576 - val_loss: 20.2371 - val_Real_acc: 6.5628\n",
      "Epoch 310/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 17.0654 - Real_acc: 5.4589 - val_loss: 21.9808 - val_Real_acc: 6.7666\n",
      "Epoch 311/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 19.0373 - Real_acc: 5.3485 - val_loss: 20.6747 - val_Real_acc: 6.8519\n",
      "Epoch 312/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.4204 - Real_acc: 5.3418 - val_loss: 20.8727 - val_Real_acc: 6.7790\n",
      "Epoch 313/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.4404 - Real_acc: 5.3428 - val_loss: 19.8369 - val_Real_acc: 6.3380\n",
      "Epoch 314/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.3068 - Real_acc: 5.2480 - val_loss: 19.6778 - val_Real_acc: 6.3365\n",
      "Epoch 315/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.3473 - Real_acc: 5.3924 - val_loss: 19.9447 - val_Real_acc: 7.0197\n",
      "Epoch 316/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.3602 - Real_acc: 5.3850 - val_loss: 19.4623 - val_Real_acc: 6.1562\n",
      "Epoch 317/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.2550 - Real_acc: 5.2379 - val_loss: 19.6357 - val_Real_acc: 6.2955\n",
      "Epoch 318/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.2119 - Real_acc: 5.3737 - val_loss: 20.2590 - val_Real_acc: 6.5132\n",
      "Epoch 319/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.1829 - Real_acc: 5.3022 - val_loss: 19.3838 - val_Real_acc: 6.3866\n",
      "Epoch 320/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.1110 - Real_acc: 5.3040 - val_loss: 19.5044 - val_Real_acc: 6.6931\n",
      "Epoch 321/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.1458 - Real_acc: 5.3811 - val_loss: 19.3286 - val_Real_acc: 6.2960\n",
      "Epoch 322/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.1466 - Real_acc: 5.2923 - val_loss: 19.3221 - val_Real_acc: 6.3385\n",
      "Epoch 323/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 18.0779 - Real_acc: 5.4639 - val_loss: 19.1181 - val_Real_acc: 6.5507\n",
      "Epoch 324/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.9363 - Real_acc: 5.4279 - val_loss: 19.1490 - val_Real_acc: 6.2595\n",
      "Epoch 325/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.8695 - Real_acc: 5.2717 - val_loss: 18.7000 - val_Real_acc: 7.0493\n",
      "Epoch 326/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.8134 - Real_acc: 5.3044 - val_loss: 18.8460 - val_Real_acc: 6.2652\n",
      "Epoch 327/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.7473 - Real_acc: 5.2475 - val_loss: 18.9062 - val_Real_acc: 6.2610\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 15.6742 - Real_acc: 5.2902 - val_loss: 18.7294 - val_Real_acc: 6.1423\n",
      "Epoch 329/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.6251 - Real_acc: 5.3115 - val_loss: 18.3358 - val_Real_acc: 6.7515\n",
      "Epoch 330/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.5805 - Real_acc: 5.0986 - val_loss: 18.4380 - val_Real_acc: 6.2418\n",
      "Epoch 331/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.5771 - Real_acc: 5.1158 - val_loss: 18.7958 - val_Real_acc: 6.3174\n",
      "Epoch 332/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.5779 - Real_acc: 5.2459 - val_loss: 18.5063 - val_Real_acc: 6.5304\n",
      "Epoch 333/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.5452 - Real_acc: 5.3130 - val_loss: 18.6344 - val_Real_acc: 6.4937\n",
      "Epoch 334/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.8049 - Real_acc: 5.1638 - val_loss: 18.4986 - val_Real_acc: 6.2289\n",
      "Epoch 335/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.5731 - Real_acc: 5.2747 - val_loss: 18.4748 - val_Real_acc: 6.1317\n",
      "Epoch 336/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.3380 - Real_acc: 5.2978 - val_loss: 18.7690 - val_Real_acc: 6.1431\n",
      "Epoch 337/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.8172 - Real_acc: 5.2119 - val_loss: 17.8615 - val_Real_acc: 6.3950\n",
      "Epoch 338/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.2956 - Real_acc: 5.2279 - val_loss: 17.8512 - val_Real_acc: 6.3405\n",
      "Epoch 339/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.3123 - Real_acc: 5.1596 - val_loss: 18.0797 - val_Real_acc: 6.2921\n",
      "Epoch 340/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.1924 - Real_acc: 5.1099 - val_loss: 17.6892 - val_Real_acc: 6.0663\n",
      "Epoch 341/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.1317 - Real_acc: 5.2147 - val_loss: 17.8238 - val_Real_acc: 6.1522\n",
      "Epoch 342/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.0967 - Real_acc: 5.0846 - val_loss: 17.5936 - val_Real_acc: 6.4010\n",
      "Epoch 343/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.1491 - Real_acc: 5.3760 - val_loss: 17.3962 - val_Real_acc: 6.1421\n",
      "Epoch 344/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.1082 - Real_acc: 5.2326 - val_loss: 17.3703 - val_Real_acc: 6.0785\n",
      "Epoch 345/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.9556 - Real_acc: 5.1969 - val_loss: 17.5205 - val_Real_acc: 7.0290\n",
      "Epoch 346/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.0588 - Real_acc: 5.1139 - val_loss: 17.8575 - val_Real_acc: 6.2500\n",
      "Epoch 347/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.7015 - Real_acc: 5.2314 - val_loss: 17.2648 - val_Real_acc: 6.3440\n",
      "Epoch 348/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.8266 - Real_acc: 5.0907 - val_loss: 17.4793 - val_Real_acc: 6.5870\n",
      "Epoch 349/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.7629 - Real_acc: 5.1913 - val_loss: 17.6359 - val_Real_acc: 6.3316\n",
      "Epoch 350/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.7981 - Real_acc: 5.1738 - val_loss: 17.2166 - val_Real_acc: 6.4651\n",
      "Epoch 351/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.9103 - Real_acc: 5.0506 - val_loss: 17.1955 - val_Real_acc: 6.1832\n",
      "Epoch 352/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.8938 - Real_acc: 5.2787 - val_loss: 17.0573 - val_Real_acc: 6.1874\n",
      "Epoch 353/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.7149 - Real_acc: 5.2336 - val_loss: 16.9862 - val_Real_acc: 6.2216\n",
      "Epoch 354/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.6639 - Real_acc: 5.1694 - val_loss: 17.1285 - val_Real_acc: 6.3300\n",
      "Epoch 355/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.6304 - Real_acc: 5.0526 - val_loss: 16.9564 - val_Real_acc: 6.3771\n",
      "Epoch 356/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.5531 - Real_acc: 5.1380 - val_loss: 16.8335 - val_Real_acc: 6.2997\n",
      "Epoch 357/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.3394 - Real_acc: 5.0533 - val_loss: 16.8186 - val_Real_acc: 6.1065\n",
      "Epoch 358/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.0381 - Real_acc: 5.2956 - val_loss: 16.8555 - val_Real_acc: 6.7399\n",
      "Epoch 359/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.4859 - Real_acc: 5.1352 - val_loss: 16.7408 - val_Real_acc: 6.0363\n",
      "Epoch 360/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.4521 - Real_acc: 5.0585 - val_loss: 16.7519 - val_Real_acc: 6.0509\n",
      "Epoch 361/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.3868 - Real_acc: 5.0768 - val_loss: 16.5000 - val_Real_acc: 6.0535\n",
      "Epoch 362/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.3915 - Real_acc: 5.0734 - val_loss: 16.5999 - val_Real_acc: 6.1914\n",
      "Epoch 363/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.3301 - Real_acc: 5.1099 - val_loss: 16.2301 - val_Real_acc: 6.0723\n",
      "Epoch 364/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.1661 - Real_acc: 5.0408 - val_loss: 16.3526 - val_Real_acc: 6.0894\n",
      "Epoch 365/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.2782 - Real_acc: 5.1809 - val_loss: 16.2832 - val_Real_acc: 6.6722\n",
      "Epoch 366/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.2875 - Real_acc: 5.3068 - val_loss: 16.7299 - val_Real_acc: 6.1848\n",
      "Epoch 367/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 15.1289 - Real_acc: 5.0580 - val_loss: 16.5269 - val_Real_acc: 6.3499\n",
      "Epoch 368/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.3299 - Real_acc: 5.1682 - val_loss: 16.4016 - val_Real_acc: 6.4694\n",
      "Epoch 369/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.1371 - Real_acc: 5.1524 - val_loss: 16.2273 - val_Real_acc: 6.1050\n",
      "Epoch 370/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.1491 - Real_acc: 5.0282 - val_loss: 16.4013 - val_Real_acc: 6.2038\n",
      "Epoch 371/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.2136 - Real_acc: 5.1357 - val_loss: 15.9034 - val_Real_acc: 6.1093\n",
      "Epoch 372/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.0558 - Real_acc: 5.1801 - val_loss: 15.9396 - val_Real_acc: 6.0494\n",
      "Epoch 373/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.3671 - Real_acc: 5.1110 - val_loss: 16.2649 - val_Real_acc: 6.3785\n",
      "Epoch 374/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.0451 - Real_acc: 5.1367 - val_loss: 16.1753 - val_Real_acc: 6.1358\n",
      "Epoch 375/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.9925 - Real_acc: 5.0672 - val_loss: 15.8345 - val_Real_acc: 6.2021\n",
      "Epoch 376/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.0037 - Real_acc: 5.1392 - val_loss: 16.2315 - val_Real_acc: 6.3398\n",
      "Epoch 377/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.9570 - Real_acc: 4.9916 - val_loss: 15.6220 - val_Real_acc: 6.0884\n",
      "Epoch 378/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.7385 - Real_acc: 5.0381 - val_loss: 15.7473 - val_Real_acc: 6.3883\n",
      "Epoch 379/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.8547 - Real_acc: 5.2139 - val_loss: 15.7006 - val_Real_acc: 6.1297\n",
      "Epoch 380/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.9129 - Real_acc: 5.0606 - val_loss: 15.6330 - val_Real_acc: 6.1636\n",
      "Epoch 381/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.7610 - Real_acc: 5.1289 - val_loss: 15.7464 - val_Real_acc: 6.1396\n",
      "Epoch 382/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.7090 - Real_acc: 5.2365 - val_loss: 15.6152 - val_Real_acc: 6.1886\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 13.7627 - Real_acc: 5.1718 - val_loss: 15.7038 - val_Real_acc: 6.0593\n",
      "Epoch 384/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 16.9455 - Real_acc: 5.1323 - val_loss: 15.4734 - val_Real_acc: 6.0010\n",
      "Epoch 385/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.5076 - Real_acc: 5.0054 - val_loss: 15.8101 - val_Real_acc: 6.2417\n",
      "Epoch 386/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.4541 - Real_acc: 5.2507 - val_loss: 15.4359 - val_Real_acc: 6.1400\n",
      "Epoch 387/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.4932 - Real_acc: 5.1246 - val_loss: 15.4037 - val_Real_acc: 6.3501\n",
      "Epoch 388/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.6731 - Real_acc: 5.0637 - val_loss: 15.7111 - val_Real_acc: 6.4277\n",
      "Epoch 389/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.6553 - Real_acc: 5.0694 - val_loss: 15.5996 - val_Real_acc: 6.1293\n",
      "Epoch 390/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.4289 - Real_acc: 5.0566 - val_loss: 15.2399 - val_Real_acc: 6.4348\n",
      "Epoch 391/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.3724 - Real_acc: 5.0507 - val_loss: 15.3387 - val_Real_acc: 6.1117\n",
      "Epoch 392/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.3123 - Real_acc: 5.1620 - val_loss: 15.8771 - val_Real_acc: 6.3724\n",
      "Epoch 393/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.3152 - Real_acc: 5.0528 - val_loss: 15.0842 - val_Real_acc: 6.1262\n",
      "Epoch 394/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.3658 - Real_acc: 5.0389 - val_loss: 15.0912 - val_Real_acc: 6.1766\n",
      "Epoch 395/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.1252 - Real_acc: 5.0282 - val_loss: 15.6641 - val_Real_acc: 6.0421\n",
      "Epoch 396/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.3653 - Real_acc: 5.0112 - val_loss: 14.9415 - val_Real_acc: 6.2638\n",
      "Epoch 397/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.0931 - Real_acc: 5.0959 - val_loss: 14.9311 - val_Real_acc: 6.2166\n",
      "Epoch 398/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.0280 - Real_acc: 5.1163 - val_loss: 14.9607 - val_Real_acc: 6.2174\n",
      "Epoch 399/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.1377 - Real_acc: 5.0281 - val_loss: 15.1459 - val_Real_acc: 6.4681\n",
      "Epoch 400/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.5770 - Real_acc: 5.1937 - val_loss: 14.7319 - val_Real_acc: 6.1850\n",
      "Epoch 401/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.9500 - Real_acc: 5.0113 - val_loss: 15.5788 - val_Real_acc: 6.2034\n",
      "Epoch 402/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.0023 - Real_acc: 5.0380 - val_loss: 14.9266 - val_Real_acc: 6.1677\n",
      "Epoch 403/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.0154 - Real_acc: 5.0338 - val_loss: 14.7591 - val_Real_acc: 6.5890\n",
      "Epoch 404/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.0222 - Real_acc: 5.2316 - val_loss: 14.7420 - val_Real_acc: 6.2189\n",
      "Epoch 405/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.9572 - Real_acc: 4.9969 - val_loss: 14.4962 - val_Real_acc: 6.3212\n",
      "Epoch 406/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.1206 - Real_acc: 5.2118 - val_loss: 15.2434 - val_Real_acc: 6.1415\n",
      "Epoch 407/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.9234 - Real_acc: 5.1310 - val_loss: 14.5255 - val_Real_acc: 6.3268\n",
      "Epoch 408/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7525 - Real_acc: 5.0727 - val_loss: 14.7590 - val_Real_acc: 6.2061\n",
      "Epoch 409/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 14.0060 - Real_acc: 5.1488 - val_loss: 14.7619 - val_Real_acc: 6.1718\n",
      "Epoch 410/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.8434 - Real_acc: 5.0749 - val_loss: 14.5316 - val_Real_acc: 6.2474\n",
      "Epoch 411/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7625 - Real_acc: 5.0044 - val_loss: 14.2458 - val_Real_acc: 6.1118\n",
      "Epoch 412/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7145 - Real_acc: 4.9744 - val_loss: 14.4065 - val_Real_acc: 6.4542\n",
      "Epoch 413/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7987 - Real_acc: 5.0359 - val_loss: 14.3337 - val_Real_acc: 6.2323\n",
      "Epoch 414/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.8013 - Real_acc: 5.0326 - val_loss: 14.5448 - val_Real_acc: 6.1666\n",
      "Epoch 415/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7040 - Real_acc: 5.0231 - val_loss: 14.1055 - val_Real_acc: 6.0305\n",
      "Epoch 416/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.6010 - Real_acc: 4.9825 - val_loss: 14.0859 - val_Real_acc: 6.2578\n",
      "Epoch 417/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7096 - Real_acc: 5.1264 - val_loss: 14.5822 - val_Real_acc: 6.3105\n",
      "Epoch 418/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.4504 - Real_acc: 5.2332 - val_loss: 14.1283 - val_Real_acc: 6.0740\n",
      "Epoch 419/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.6067 - Real_acc: 5.0193 - val_loss: 14.0099 - val_Real_acc: 6.1180\n",
      "Epoch 420/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4947 - Real_acc: 5.0536 - val_loss: 13.9404 - val_Real_acc: 6.0935\n",
      "Epoch 421/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.5160 - Real_acc: 5.0242 - val_loss: 14.4033 - val_Real_acc: 6.2015\n",
      "Epoch 422/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4397 - Real_acc: 5.0409 - val_loss: 14.0899 - val_Real_acc: 6.1071\n",
      "Epoch 423/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4912 - Real_acc: 5.0800 - val_loss: 14.3058 - val_Real_acc: 6.1897\n",
      "Epoch 424/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.6547 - Real_acc: 5.0640 - val_loss: 15.2026 - val_Real_acc: 6.3872\n",
      "Epoch 425/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.6798 - Real_acc: 5.0424 - val_loss: 13.6496 - val_Real_acc: 6.0836\n",
      "Epoch 426/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4777 - Real_acc: 5.0532 - val_loss: 14.2440 - val_Real_acc: 6.5547\n",
      "Epoch 427/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4092 - Real_acc: 4.9858 - val_loss: 13.6831 - val_Real_acc: 6.0705\n",
      "Epoch 428/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4308 - Real_acc: 5.0247 - val_loss: 13.5382 - val_Real_acc: 6.0527\n",
      "Epoch 429/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.2159 - Real_acc: 4.9617 - val_loss: 13.8289 - val_Real_acc: 6.2635\n",
      "Epoch 430/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4204 - Real_acc: 5.2480 - val_loss: 13.7771 - val_Real_acc: 6.1137\n",
      "Epoch 431/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.2122 - Real_acc: 4.9771 - val_loss: 13.6715 - val_Real_acc: 6.0494\n",
      "Epoch 432/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.2347 - Real_acc: 5.0815 - val_loss: 13.6244 - val_Real_acc: 6.4642\n",
      "Epoch 433/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4627 - Real_acc: 5.1392 - val_loss: 14.1395 - val_Real_acc: 6.2000\n",
      "Epoch 434/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.2471 - Real_acc: 5.0913 - val_loss: 13.7062 - val_Real_acc: 6.1408\n",
      "Epoch 435/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.1322 - Real_acc: 5.0764 - val_loss: 13.4141 - val_Real_acc: 6.0479\n",
      "Epoch 436/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.1286 - Real_acc: 5.0371 - val_loss: 13.6702 - val_Real_acc: 6.1984\n",
      "Epoch 437/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.7196 - Real_acc: 5.0541 - val_loss: 13.7582 - val_Real_acc: 6.0390\n",
      "Epoch 438/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 11.9465 - Real_acc: 4.8830 - val_loss: 13.3435 - val_Real_acc: 6.0613\n",
      "Epoch 439/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.9510 - Real_acc: 5.1172 - val_loss: 13.2178 - val_Real_acc: 5.9596\n",
      "Epoch 440/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.9876 - Real_acc: 5.0071 - val_loss: 13.2209 - val_Real_acc: 6.0168\n",
      "Epoch 441/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.2717 - Real_acc: 4.9619 - val_loss: 13.3692 - val_Real_acc: 6.2583\n",
      "Epoch 442/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.9583 - Real_acc: 5.0800 - val_loss: 13.0835 - val_Real_acc: 6.1244\n",
      "Epoch 443/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.8750 - Real_acc: 4.9373 - val_loss: 13.2274 - val_Real_acc: 6.0316\n",
      "Epoch 444/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.8745 - Real_acc: 4.9395 - val_loss: 13.0381 - val_Real_acc: 6.0223\n",
      "Epoch 445/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.0853 - Real_acc: 4.9816 - val_loss: 13.2572 - val_Real_acc: 6.0366\n",
      "Epoch 446/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.6976 - Real_acc: 4.8829 - val_loss: 13.0886 - val_Real_acc: 6.3782\n",
      "Epoch 447/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.7161 - Real_acc: 4.8863 - val_loss: 12.9781 - val_Real_acc: 5.9305\n",
      "Epoch 448/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4923 - Real_acc: 5.0365 - val_loss: 13.4792 - val_Real_acc: 5.9619\n",
      "Epoch 449/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.7211 - Real_acc: 4.9397 - val_loss: 12.9146 - val_Real_acc: 6.0105\n",
      "Epoch 450/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.7887 - Real_acc: 5.0103 - val_loss: 12.8783 - val_Real_acc: 5.9746\n",
      "Epoch 451/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.6918 - Real_acc: 4.9264 - val_loss: 12.8758 - val_Real_acc: 5.9316\n",
      "Epoch 452/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.1643 - Real_acc: 5.0857 - val_loss: 12.7719 - val_Real_acc: 5.9524\n",
      "Epoch 453/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.6135 - Real_acc: 4.8555 - val_loss: 12.9467 - val_Real_acc: 5.9340\n",
      "Epoch 454/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.6458 - Real_acc: 5.0214 - val_loss: 12.6813 - val_Real_acc: 6.3185\n",
      "Epoch 455/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.6002 - Real_acc: 4.9975 - val_loss: 12.7670 - val_Real_acc: 5.9690\n",
      "Epoch 456/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.5910 - Real_acc: 4.9254 - val_loss: 12.6425 - val_Real_acc: 5.9574\n",
      "Epoch 457/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 13.2132 - Real_acc: 5.0644 - val_loss: 14.1476 - val_Real_acc: 6.1820\n",
      "Epoch 458/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.7645 - Real_acc: 4.9118 - val_loss: 12.7513 - val_Real_acc: 5.9963\n",
      "Epoch 459/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4862 - Real_acc: 4.8958 - val_loss: 12.6281 - val_Real_acc: 5.9432\n",
      "Epoch 460/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3960 - Real_acc: 4.8605 - val_loss: 12.6256 - val_Real_acc: 5.9056\n",
      "Epoch 461/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.5059 - Real_acc: 4.9094 - val_loss: 12.9752 - val_Real_acc: 6.1937\n",
      "Epoch 462/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.9507 - Real_acc: 4.9348 - val_loss: 13.1525 - val_Real_acc: 6.2024\n",
      "Epoch 463/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4011 - Real_acc: 4.8282 - val_loss: 12.7305 - val_Real_acc: 6.0855\n",
      "Epoch 464/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3515 - Real_acc: 4.9311 - val_loss: 12.4939 - val_Real_acc: 5.9428\n",
      "Epoch 465/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4334 - Real_acc: 4.9581 - val_loss: 12.5325 - val_Real_acc: 5.9257\n",
      "Epoch 466/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3230 - Real_acc: 4.8908 - val_loss: 12.4665 - val_Real_acc: 5.8499\n",
      "Epoch 467/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4675 - Real_acc: 5.0920 - val_loss: 12.4447 - val_Real_acc: 5.8642\n",
      "Epoch 468/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4006 - Real_acc: 4.9479 - val_loss: 12.3132 - val_Real_acc: 5.8807\n",
      "Epoch 469/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3020 - Real_acc: 4.9105 - val_loss: 12.3563 - val_Real_acc: 5.9820\n",
      "Epoch 470/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3681 - Real_acc: 4.8770 - val_loss: 12.3957 - val_Real_acc: 5.9222\n",
      "Epoch 471/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4781 - Real_acc: 4.8095 - val_loss: 12.8455 - val_Real_acc: 5.8998\n",
      "Epoch 472/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4726 - Real_acc: 4.8407 - val_loss: 12.0827 - val_Real_acc: 6.0352\n",
      "Epoch 473/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3033 - Real_acc: 4.8136 - val_loss: 12.2774 - val_Real_acc: 5.8864\n",
      "Epoch 474/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3765 - Real_acc: 4.7613 - val_loss: 12.0539 - val_Real_acc: 5.7793\n",
      "Epoch 475/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1412 - Real_acc: 4.9032 - val_loss: 12.3241 - val_Real_acc: 5.7995\n",
      "Epoch 476/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3343 - Real_acc: 4.8143 - val_loss: 12.5476 - val_Real_acc: 5.9158\n",
      "Epoch 477/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1110 - Real_acc: 4.8227 - val_loss: 12.1290 - val_Real_acc: 5.8073\n",
      "Epoch 478/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1410 - Real_acc: 4.7827 - val_loss: 12.1404 - val_Real_acc: 5.7312\n",
      "Epoch 479/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.0723 - Real_acc: 4.7876 - val_loss: 12.2941 - val_Real_acc: 6.1930\n",
      "Epoch 480/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.0912 - Real_acc: 4.9107 - val_loss: 12.2704 - val_Real_acc: 6.0090\n",
      "Epoch 481/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1115 - Real_acc: 4.7173 - val_loss: 12.2255 - val_Real_acc: 5.9498\n",
      "Epoch 482/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.0063 - Real_acc: 4.6767 - val_loss: 12.2204 - val_Real_acc: 5.7817\n",
      "Epoch 483/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4039 - Real_acc: 4.8172 - val_loss: 11.9029 - val_Real_acc: 5.7578\n",
      "Epoch 484/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.4219 - Real_acc: 4.9110 - val_loss: 11.7646 - val_Real_acc: 5.6640\n",
      "Epoch 485/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.0975 - Real_acc: 4.8119 - val_loss: 11.7212 - val_Real_acc: 5.6928\n",
      "Epoch 486/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.8745 - Real_acc: 4.8123 - val_loss: 11.7365 - val_Real_acc: 5.6990\n",
      "Epoch 487/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1576 - Real_acc: 4.9665 - val_loss: 11.8551 - val_Real_acc: 5.6842\n",
      "Epoch 488/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.2405 - Real_acc: 4.7399 - val_loss: 11.7248 - val_Real_acc: 5.6679\n",
      "Epoch 489/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.8294 - Real_acc: 4.7231 - val_loss: 11.6086 - val_Real_acc: 5.6123\n",
      "Epoch 490/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7981 - Real_acc: 4.7085 - val_loss: 11.7150 - val_Real_acc: 5.6374\n",
      "Epoch 491/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1408 - Real_acc: 4.7503 - val_loss: 12.4372 - val_Real_acc: 5.7152\n",
      "Epoch 492/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 12.4884 - Real_acc: 4.8087 - val_loss: 11.5529 - val_Real_acc: 5.6991\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7283 - Real_acc: 4.7126 - val_loss: 11.5495 - val_Real_acc: 5.5704\n",
      "Epoch 494/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7159 - Real_acc: 4.6723 - val_loss: 11.5202 - val_Real_acc: 5.6437\n",
      "Epoch 495/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.8416 - Real_acc: 4.6977 - val_loss: 11.5161 - val_Real_acc: 5.6340\n",
      "Epoch 496/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7727 - Real_acc: 4.6599 - val_loss: 11.8033 - val_Real_acc: 5.8117\n",
      "Epoch 497/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7162 - Real_acc: 4.7062 - val_loss: 11.8612 - val_Real_acc: 5.6950\n",
      "Epoch 498/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.9726 - Real_acc: 4.6793 - val_loss: 11.7705 - val_Real_acc: 5.6738\n",
      "Epoch 499/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.1475 - Real_acc: 4.8397 - val_loss: 11.6120 - val_Real_acc: 5.5189\n",
      "Epoch 500/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6458 - Real_acc: 4.6575 - val_loss: 11.4640 - val_Real_acc: 5.5071\n",
      "Epoch 501/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7017 - Real_acc: 4.5882 - val_loss: 11.8353 - val_Real_acc: 5.5952\n",
      "Epoch 502/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.9170 - Real_acc: 4.5504 - val_loss: 11.3047 - val_Real_acc: 5.5789\n",
      "Epoch 503/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6859 - Real_acc: 4.5785 - val_loss: 11.7881 - val_Real_acc: 5.6255\n",
      "Epoch 504/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6576 - Real_acc: 4.6564 - val_loss: 11.2934 - val_Real_acc: 5.6444\n",
      "Epoch 505/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.5576 - Real_acc: 4.5869 - val_loss: 11.4545 - val_Real_acc: 5.5404\n",
      "Epoch 506/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.5472 - Real_acc: 4.6351 - val_loss: 11.2680 - val_Real_acc: 5.4510\n",
      "Epoch 507/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.8069 - Real_acc: 4.6651 - val_loss: 11.3495 - val_Real_acc: 5.7695\n",
      "Epoch 508/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6228 - Real_acc: 4.6105 - val_loss: 11.2327 - val_Real_acc: 5.6431\n",
      "Epoch 509/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6414 - Real_acc: 4.5989 - val_loss: 11.6744 - val_Real_acc: 5.5918\n",
      "Epoch 510/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.4951 - Real_acc: 4.6265 - val_loss: 11.5665 - val_Real_acc: 5.5605\n",
      "Epoch 511/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6855 - Real_acc: 4.6045 - val_loss: 11.3663 - val_Real_acc: 5.4812\n",
      "Epoch 512/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.5972 - Real_acc: 4.4709 - val_loss: 11.0684 - val_Real_acc: 5.4423\n",
      "Epoch 513/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.0841 - Real_acc: 4.5741 - val_loss: 11.2824 - val_Real_acc: 5.5837\n",
      "Epoch 514/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.5227 - Real_acc: 4.5653 - val_loss: 11.0933 - val_Real_acc: 5.4327\n",
      "Epoch 515/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.3361 - Real_acc: 4.4745 - val_loss: 11.2398 - val_Real_acc: 5.4267\n",
      "Epoch 516/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.5370 - Real_acc: 4.5150 - val_loss: 11.4644 - val_Real_acc: 5.4883\n",
      "Epoch 517/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.8489 - Real_acc: 4.5355 - val_loss: 11.1449 - val_Real_acc: 5.4288\n",
      "Epoch 518/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.4417 - Real_acc: 4.5386 - val_loss: 10.9669 - val_Real_acc: 5.5216\n",
      "Epoch 519/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.3812 - Real_acc: 4.5772 - val_loss: 11.5487 - val_Real_acc: 5.7913\n",
      "Epoch 520/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.4837 - Real_acc: 4.4778 - val_loss: 11.0087 - val_Real_acc: 5.4419\n",
      "Epoch 521/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2838 - Real_acc: 4.4456 - val_loss: 11.1729 - val_Real_acc: 5.3475\n",
      "Epoch 522/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.3333 - Real_acc: 4.5126 - val_loss: 10.8828 - val_Real_acc: 5.2468\n",
      "Epoch 523/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2632 - Real_acc: 4.4894 - val_loss: 10.8252 - val_Real_acc: 5.2574\n",
      "Epoch 524/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2748 - Real_acc: 4.4251 - val_loss: 11.0230 - val_Real_acc: 5.3845\n",
      "Epoch 525/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.7958 - Real_acc: 4.4835 - val_loss: 11.0271 - val_Real_acc: 5.4890\n",
      "Epoch 526/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.1978 - Real_acc: 4.3008 - val_loss: 10.8375 - val_Real_acc: 5.2928\n",
      "Epoch 527/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2046 - Real_acc: 4.4143 - val_loss: 11.0106 - val_Real_acc: 5.4241\n",
      "Epoch 528/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2493 - Real_acc: 4.3974 - val_loss: 10.9367 - val_Real_acc: 5.5626\n",
      "Epoch 529/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.1848 - Real_acc: 4.4427 - val_loss: 10.9353 - val_Real_acc: 5.2273\n",
      "Epoch 530/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2164 - Real_acc: 4.3894 - val_loss: 10.9181 - val_Real_acc: 5.2389\n",
      "Epoch 531/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.3643 - Real_acc: 4.4991 - val_loss: 11.1453 - val_Real_acc: 5.2743\n",
      "Epoch 532/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.4573 - Real_acc: 4.4459 - val_loss: 10.7686 - val_Real_acc: 5.4811\n",
      "Epoch 533/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.6819 - Real_acc: 4.4824 - val_loss: 10.7001 - val_Real_acc: 5.2598\n",
      "Epoch 534/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.1569 - Real_acc: 4.3923 - val_loss: 10.8564 - val_Real_acc: 5.2330\n",
      "Epoch 535/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2599 - Real_acc: 4.3969 - val_loss: 10.7360 - val_Real_acc: 5.2366\n",
      "Epoch 536/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.2521 - Real_acc: 4.3236 - val_loss: 10.6604 - val_Real_acc: 5.2657\n",
      "Epoch 537/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.0354 - Real_acc: 4.4318 - val_loss: 10.9593 - val_Real_acc: 5.1920\n",
      "Epoch 538/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.1262 - Real_acc: 4.2531 - val_loss: 10.6410 - val_Real_acc: 5.2384\n",
      "Epoch 539/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.0339 - Real_acc: 4.2303 - val_loss: 10.6716 - val_Real_acc: 5.1657\n",
      "Epoch 540/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.1471 - Real_acc: 4.2747 - val_loss: 10.6683 - val_Real_acc: 5.2387\n",
      "Epoch 541/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.0887 - Real_acc: 4.3152 - val_loss: 10.4804 - val_Real_acc: 5.2058\n",
      "Epoch 542/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.0219 - Real_acc: 4.4347 - val_loss: 10.4949 - val_Real_acc: 5.1458\n",
      "Epoch 543/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9835 - Real_acc: 4.2337 - val_loss: 10.7253 - val_Real_acc: 5.4484\n",
      "Epoch 544/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.3513 - Real_acc: 4.3521 - val_loss: 10.6196 - val_Real_acc: 5.1617\n",
      "Epoch 545/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9470 - Real_acc: 4.2926 - val_loss: 10.5264 - val_Real_acc: 5.1265\n",
      "Epoch 546/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9291 - Real_acc: 4.3547 - val_loss: 10.8443 - val_Real_acc: 5.1544\n",
      "Epoch 547/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9357 - Real_acc: 4.3126 - val_loss: 10.5775 - val_Real_acc: 5.1687\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8927 - Real_acc: 4.2611 - val_loss: 10.3833 - val_Real_acc: 5.1014\n",
      "Epoch 549/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9140 - Real_acc: 4.2630 - val_loss: 10.5795 - val_Real_acc: 5.2555\n",
      "Epoch 550/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8451 - Real_acc: 4.3555 - val_loss: 10.4757 - val_Real_acc: 5.1951\n",
      "Epoch 551/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.9915 - Real_acc: 4.3692 - val_loss: 10.5439 - val_Real_acc: 5.1211\n",
      "Epoch 552/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8980 - Real_acc: 4.2590 - val_loss: 10.3648 - val_Real_acc: 5.0770\n",
      "Epoch 553/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8579 - Real_acc: 4.3110 - val_loss: 10.4979 - val_Real_acc: 5.1347\n",
      "Epoch 554/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7932 - Real_acc: 4.2825 - val_loss: 10.2425 - val_Real_acc: 5.0397\n",
      "Epoch 555/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8111 - Real_acc: 4.3031 - val_loss: 10.4701 - val_Real_acc: 5.1937\n",
      "Epoch 556/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8065 - Real_acc: 4.2731 - val_loss: 10.6652 - val_Real_acc: 5.5960\n",
      "Epoch 557/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7953 - Real_acc: 4.2157 - val_loss: 10.3865 - val_Real_acc: 5.0287\n",
      "Epoch 558/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.3925 - Real_acc: 4.3279 - val_loss: 10.3760 - val_Real_acc: 5.0549\n",
      "Epoch 559/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.0104 - Real_acc: 4.2050 - val_loss: 10.2546 - val_Real_acc: 5.0119\n",
      "Epoch 560/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8368 - Real_acc: 4.2436 - val_loss: 10.2869 - val_Real_acc: 5.0742\n",
      "Epoch 561/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7932 - Real_acc: 4.2845 - val_loss: 10.5696 - val_Real_acc: 5.0310\n",
      "Epoch 562/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7294 - Real_acc: 4.2407 - val_loss: 10.2331 - val_Real_acc: 5.1759\n",
      "Epoch 563/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7088 - Real_acc: 4.2558 - val_loss: 10.3570 - val_Real_acc: 5.1853\n",
      "Epoch 564/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8274 - Real_acc: 4.2355 - val_loss: 10.2637 - val_Real_acc: 5.0281\n",
      "Epoch 565/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6561 - Real_acc: 4.2305 - val_loss: 10.4509 - val_Real_acc: 5.0445\n",
      "Epoch 566/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7095 - Real_acc: 4.1542 - val_loss: 10.3674 - val_Real_acc: 5.1926\n",
      "Epoch 567/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 11.2163 - Real_acc: 4.3144 - val_loss: 10.2079 - val_Real_acc: 5.3464\n",
      "Epoch 568/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7410 - Real_acc: 4.1606 - val_loss: 10.0747 - val_Real_acc: 4.9414\n",
      "Epoch 569/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6600 - Real_acc: 4.1825 - val_loss: 10.1060 - val_Real_acc: 5.7419\n",
      "Epoch 570/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6712 - Real_acc: 4.1836 - val_loss: 10.3171 - val_Real_acc: 5.0541\n",
      "Epoch 571/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5922 - Real_acc: 4.1846 - val_loss: 10.1921 - val_Real_acc: 5.2116\n",
      "Epoch 572/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8083 - Real_acc: 4.2643 - val_loss: 12.1219 - val_Real_acc: 5.9918\n",
      "Epoch 573/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 10.9418 - Real_acc: 4.1870 - val_loss: 10.0666 - val_Real_acc: 4.9700\n",
      "Epoch 574/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5574 - Real_acc: 4.1823 - val_loss: 9.9930 - val_Real_acc: 4.8829\n",
      "Epoch 575/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5772 - Real_acc: 4.1698 - val_loss: 10.1559 - val_Real_acc: 5.0328\n",
      "Epoch 576/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5718 - Real_acc: 4.1659 - val_loss: 10.0095 - val_Real_acc: 4.9644\n",
      "Epoch 577/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5462 - Real_acc: 4.2212 - val_loss: 9.9450 - val_Real_acc: 4.8915\n",
      "Epoch 578/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5537 - Real_acc: 4.3204 - val_loss: 9.9450 - val_Real_acc: 4.9169\n",
      "Epoch 579/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5046 - Real_acc: 4.1125 - val_loss: 9.9922 - val_Real_acc: 5.2192\n",
      "Epoch 580/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5423 - Real_acc: 4.1466 - val_loss: 9.9154 - val_Real_acc: 4.8881\n",
      "Epoch 581/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4734 - Real_acc: 4.1238 - val_loss: 10.0435 - val_Real_acc: 4.8835\n",
      "Epoch 582/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5064 - Real_acc: 4.1108 - val_loss: 9.9736 - val_Real_acc: 4.9975\n",
      "Epoch 583/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6123 - Real_acc: 4.2151 - val_loss: 9.9240 - val_Real_acc: 4.9374\n",
      "Epoch 584/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5159 - Real_acc: 4.2646 - val_loss: 9.8769 - val_Real_acc: 4.8182\n",
      "Epoch 585/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6669 - Real_acc: 4.1180 - val_loss: 10.0530 - val_Real_acc: 5.0212\n",
      "Epoch 586/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4998 - Real_acc: 4.1366 - val_loss: 9.9703 - val_Real_acc: 4.9297\n",
      "Epoch 587/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8260 - Real_acc: 4.1174 - val_loss: 10.5506 - val_Real_acc: 5.0681\n",
      "Epoch 588/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5242 - Real_acc: 4.1826 - val_loss: 9.9437 - val_Real_acc: 4.8426\n",
      "Epoch 589/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.7156 - Real_acc: 4.1092 - val_loss: 9.9415 - val_Real_acc: 4.8731\n",
      "Epoch 590/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4988 - Real_acc: 4.0937 - val_loss: 9.8496 - val_Real_acc: 4.7628\n",
      "Epoch 591/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5043 - Real_acc: 4.1070 - val_loss: 10.0590 - val_Real_acc: 4.9100\n",
      "Epoch 592/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4573 - Real_acc: 4.1173 - val_loss: 9.7831 - val_Real_acc: 4.8597\n",
      "Epoch 593/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4461 - Real_acc: 4.0835 - val_loss: 9.8137 - val_Real_acc: 4.8387\n",
      "Epoch 594/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3904 - Real_acc: 4.1559 - val_loss: 9.9971 - val_Real_acc: 4.8854\n",
      "Epoch 595/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5322 - Real_acc: 4.1531 - val_loss: 9.9760 - val_Real_acc: 5.0269\n",
      "Epoch 596/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4787 - Real_acc: 4.0809 - val_loss: 9.7874 - val_Real_acc: 4.8045\n",
      "Epoch 597/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5846 - Real_acc: 4.0625 - val_loss: 9.8449 - val_Real_acc: 4.8436\n",
      "Epoch 598/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2833 - Real_acc: 4.0547 - val_loss: 9.9612 - val_Real_acc: 4.8009\n",
      "Epoch 599/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5690 - Real_acc: 4.1333 - val_loss: 10.1755 - val_Real_acc: 4.9496\n",
      "Epoch 600/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5094 - Real_acc: 4.1522 - val_loss: 9.8155 - val_Real_acc: 4.7599\n",
      "Epoch 601/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4203 - Real_acc: 4.0145 - val_loss: 9.6603 - val_Real_acc: 4.6814\n",
      "Epoch 602/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2956 - Real_acc: 4.0148 - val_loss: 9.7243 - val_Real_acc: 4.7275\n",
      "Epoch 603/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4197 - Real_acc: 4.1049 - val_loss: 9.6760 - val_Real_acc: 4.6977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 604/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3791 - Real_acc: 4.0599 - val_loss: 9.6450 - val_Real_acc: 4.7637\n",
      "Epoch 605/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.4836 - Real_acc: 4.1279 - val_loss: 10.2013 - val_Real_acc: 4.9449\n",
      "Epoch 606/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.8911 - Real_acc: 4.0669 - val_loss: 9.6641 - val_Real_acc: 4.7665\n",
      "Epoch 607/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2505 - Real_acc: 4.1076 - val_loss: 9.7111 - val_Real_acc: 4.8507\n",
      "Epoch 608/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3160 - Real_acc: 4.1725 - val_loss: 9.5944 - val_Real_acc: 4.8964\n",
      "Epoch 609/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2387 - Real_acc: 4.0630 - val_loss: 9.5151 - val_Real_acc: 4.6886\n",
      "Epoch 610/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2468 - Real_acc: 3.9861 - val_loss: 9.6934 - val_Real_acc: 4.7911\n",
      "Epoch 611/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3695 - Real_acc: 4.0932 - val_loss: 9.8090 - val_Real_acc: 4.7622\n",
      "Epoch 612/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3240 - Real_acc: 4.0901 - val_loss: 9.6058 - val_Real_acc: 4.8375\n",
      "Epoch 613/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1297 - Real_acc: 4.0396 - val_loss: 9.5581 - val_Real_acc: 4.6481\n",
      "Epoch 614/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2177 - Real_acc: 3.9376 - val_loss: 9.8781 - val_Real_acc: 4.7554\n",
      "Epoch 615/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3349 - Real_acc: 3.9562 - val_loss: 9.7647 - val_Real_acc: 4.8033\n",
      "Epoch 616/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1520 - Real_acc: 3.9487 - val_loss: 9.9297 - val_Real_acc: 4.9678\n",
      "Epoch 617/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6572 - Real_acc: 4.1740 - val_loss: 9.4597 - val_Real_acc: 5.0116\n",
      "Epoch 618/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1872 - Real_acc: 4.0989 - val_loss: 9.8634 - val_Real_acc: 4.6510\n",
      "Epoch 619/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1433 - Real_acc: 4.1168 - val_loss: 9.4542 - val_Real_acc: 4.8370\n",
      "Epoch 620/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1458 - Real_acc: 4.0312 - val_loss: 9.6125 - val_Real_acc: 4.7528\n",
      "Epoch 621/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1344 - Real_acc: 3.9523 - val_loss: 9.4789 - val_Real_acc: 4.6842\n",
      "Epoch 622/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1870 - Real_acc: 3.9518 - val_loss: 9.4997 - val_Real_acc: 4.6791\n",
      "Epoch 623/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3257 - Real_acc: 4.0344 - val_loss: 9.9344 - val_Real_acc: 4.8234\n",
      "Epoch 624/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3951 - Real_acc: 3.9227 - val_loss: 9.4422 - val_Real_acc: 4.7186\n",
      "Epoch 625/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0520 - Real_acc: 4.0371 - val_loss: 9.7715 - val_Real_acc: 4.7209\n",
      "Epoch 626/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2704 - Real_acc: 4.0209 - val_loss: 9.3803 - val_Real_acc: 4.6528\n",
      "Epoch 627/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0413 - Real_acc: 3.8787 - val_loss: 9.4121 - val_Real_acc: 4.6153\n",
      "Epoch 628/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2241 - Real_acc: 4.0390 - val_loss: 9.4343 - val_Real_acc: 4.8254\n",
      "Epoch 629/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0443 - Real_acc: 3.9287 - val_loss: 9.3737 - val_Real_acc: 4.7241\n",
      "Epoch 630/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0327 - Real_acc: 3.9672 - val_loss: 9.3284 - val_Real_acc: 4.5935\n",
      "Epoch 631/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0199 - Real_acc: 3.8820 - val_loss: 9.3705 - val_Real_acc: 4.5311\n",
      "Epoch 632/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9673 - Real_acc: 3.9742 - val_loss: 9.3705 - val_Real_acc: 4.9728\n",
      "Epoch 633/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2024 - Real_acc: 3.9674 - val_loss: 9.7717 - val_Real_acc: 4.8998\n",
      "Epoch 634/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0409 - Real_acc: 3.9447 - val_loss: 9.7132 - val_Real_acc: 4.8171\n",
      "Epoch 635/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1864 - Real_acc: 4.0129 - val_loss: 9.3364 - val_Real_acc: 4.6443\n",
      "Epoch 636/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2485 - Real_acc: 4.0400 - val_loss: 9.5398 - val_Real_acc: 4.7348\n",
      "Epoch 637/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.5451 - Real_acc: 3.9795 - val_loss: 9.8301 - val_Real_acc: 5.0073\n",
      "Epoch 638/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6713 - Real_acc: 4.0103 - val_loss: 9.2963 - val_Real_acc: 4.6629\n",
      "Epoch 639/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9321 - Real_acc: 3.9610 - val_loss: 9.4186 - val_Real_acc: 4.7155\n",
      "Epoch 640/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9164 - Real_acc: 3.9357 - val_loss: 9.2573 - val_Real_acc: 4.8514\n",
      "Epoch 641/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9793 - Real_acc: 3.8868 - val_loss: 9.4757 - val_Real_acc: 4.7866\n",
      "Epoch 642/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2525 - Real_acc: 4.0062 - val_loss: 9.5094 - val_Real_acc: 4.6994\n",
      "Epoch 643/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9483 - Real_acc: 4.0650 - val_loss: 9.2794 - val_Real_acc: 4.9388\n",
      "Epoch 644/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8886 - Real_acc: 3.9610 - val_loss: 9.1725 - val_Real_acc: 4.5376\n",
      "Epoch 645/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.1113 - Real_acc: 4.0209 - val_loss: 9.1873 - val_Real_acc: 4.6261\n",
      "Epoch 646/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.3810 - Real_acc: 4.0722 - val_loss: 9.7212 - val_Real_acc: 4.7812\n",
      "Epoch 647/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9152 - Real_acc: 3.9285 - val_loss: 9.1906 - val_Real_acc: 4.6087\n",
      "Epoch 648/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8770 - Real_acc: 3.9324 - val_loss: 9.1936 - val_Real_acc: 4.6113\n",
      "Epoch 649/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8852 - Real_acc: 3.9564 - val_loss: 9.2510 - val_Real_acc: 4.5719\n",
      "Epoch 650/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8332 - Real_acc: 3.8644 - val_loss: 9.2076 - val_Real_acc: 4.6285\n",
      "Epoch 651/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8064 - Real_acc: 3.9949 - val_loss: 9.1871 - val_Real_acc: 4.5200\n",
      "Epoch 652/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2616 - Real_acc: 3.9059 - val_loss: 9.5539 - val_Real_acc: 4.5286\n",
      "Epoch 653/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0156 - Real_acc: 3.9067 - val_loss: 9.1342 - val_Real_acc: 4.5205\n",
      "Epoch 654/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8032 - Real_acc: 3.8550 - val_loss: 9.1572 - val_Real_acc: 4.5740\n",
      "Epoch 655/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8241 - Real_acc: 4.1461 - val_loss: 9.1665 - val_Real_acc: 4.6521\n",
      "Epoch 656/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8101 - Real_acc: 3.8697 - val_loss: 9.5899 - val_Real_acc: 4.6350\n",
      "Epoch 657/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2747 - Real_acc: 3.9070 - val_loss: 9.4274 - val_Real_acc: 4.6180\n",
      "Epoch 658/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8772 - Real_acc: 3.9193 - val_loss: 9.1752 - val_Real_acc: 4.5534\n",
      "Epoch 659/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8510 - Real_acc: 3.8567 - val_loss: 9.1581 - val_Real_acc: 4.5955\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9328 - Real_acc: 3.8831 - val_loss: 9.4431 - val_Real_acc: 4.6990\n",
      "Epoch 661/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9191 - Real_acc: 3.9253 - val_loss: 9.5217 - val_Real_acc: 4.5236\n",
      "Epoch 662/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8616 - Real_acc: 3.8841 - val_loss: 9.1649 - val_Real_acc: 4.4640\n",
      "Epoch 663/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.2821 - Real_acc: 4.0106 - val_loss: 9.6976 - val_Real_acc: 4.6557\n",
      "Epoch 664/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8468 - Real_acc: 3.9172 - val_loss: 9.0460 - val_Real_acc: 4.6274\n",
      "Epoch 665/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8976 - Real_acc: 3.8767 - val_loss: 9.3041 - val_Real_acc: 4.5471\n",
      "Epoch 666/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 8.7904 - Real_acc: 3.92 - 1s 4ms/step - loss: 8.7793 - Real_acc: 3.9379 - val_loss: 9.0632 - val_Real_acc: 4.5576\n",
      "Epoch 667/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0560 - Real_acc: 3.9260 - val_loss: 9.0821 - val_Real_acc: 4.6465\n",
      "Epoch 668/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7185 - Real_acc: 3.9281 - val_loss: 9.1950 - val_Real_acc: 4.5408\n",
      "Epoch 669/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8539 - Real_acc: 3.8872 - val_loss: 9.4924 - val_Real_acc: 4.6472\n",
      "Epoch 670/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7441 - Real_acc: 4.0283 - val_loss: 9.3006 - val_Real_acc: 4.7098\n",
      "Epoch 671/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6989 - Real_acc: 3.8523 - val_loss: 8.9895 - val_Real_acc: 4.4067\n",
      "Epoch 672/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9738 - Real_acc: 3.8703 - val_loss: 9.1541 - val_Real_acc: 4.5091\n",
      "Epoch 673/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8443 - Real_acc: 3.8145 - val_loss: 9.2866 - val_Real_acc: 5.2202\n",
      "Epoch 674/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8230 - Real_acc: 3.9898 - val_loss: 8.9158 - val_Real_acc: 4.4304\n",
      "Epoch 675/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6856 - Real_acc: 3.7816 - val_loss: 9.0087 - val_Real_acc: 4.4463\n",
      "Epoch 676/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6782 - Real_acc: 3.9221 - val_loss: 9.0003 - val_Real_acc: 4.5267\n",
      "Epoch 677/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6445 - Real_acc: 3.9752 - val_loss: 9.1915 - val_Real_acc: 4.4473\n",
      "Epoch 678/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7453 - Real_acc: 3.8928 - val_loss: 9.4648 - val_Real_acc: 4.8011\n",
      "Epoch 679/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7044 - Real_acc: 3.8749 - val_loss: 9.1815 - val_Real_acc: 4.6015\n",
      "Epoch 680/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6418 - Real_acc: 3.8391 - val_loss: 9.6709 - val_Real_acc: 4.5843\n",
      "Epoch 681/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6661 - Real_acc: 3.8630 - val_loss: 8.9621 - val_Real_acc: 4.5017\n",
      "Epoch 682/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.6299 - Real_acc: 4.0872 - val_loss: 9.8483 - val_Real_acc: 4.5353\n",
      "Epoch 683/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 9.0243 - Real_acc: 4.0061 - val_loss: 8.9684 - val_Real_acc: 4.5477\n",
      "Epoch 684/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6222 - Real_acc: 3.8859 - val_loss: 9.1472 - val_Real_acc: 4.4824\n",
      "Epoch 685/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5739 - Real_acc: 3.8669 - val_loss: 8.8350 - val_Real_acc: 4.3679\n",
      "Epoch 686/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5901 - Real_acc: 3.7964 - val_loss: 8.8539 - val_Real_acc: 4.4134\n",
      "Epoch 687/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5972 - Real_acc: 3.8515 - val_loss: 8.9305 - val_Real_acc: 4.4250\n",
      "Epoch 688/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5672 - Real_acc: 3.8924 - val_loss: 9.0228 - val_Real_acc: 4.4272\n",
      "Epoch 689/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5897 - Real_acc: 3.8457 - val_loss: 9.2694 - val_Real_acc: 4.7706\n",
      "Epoch 690/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7117 - Real_acc: 3.8920 - val_loss: 9.0264 - val_Real_acc: 4.4180\n",
      "Epoch 691/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5750 - Real_acc: 3.9810 - val_loss: 9.0352 - val_Real_acc: 5.1232\n",
      "Epoch 692/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5322 - Real_acc: 3.8180 - val_loss: 8.8603 - val_Real_acc: 4.3643\n",
      "Epoch 693/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7393 - Real_acc: 3.8877 - val_loss: 8.8794 - val_Real_acc: 4.4103\n",
      "Epoch 694/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.8152 - Real_acc: 3.8947 - val_loss: 9.0876 - val_Real_acc: 4.4034\n",
      "Epoch 695/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5716 - Real_acc: 3.7481 - val_loss: 9.1828 - val_Real_acc: 4.4660\n",
      "Epoch 696/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5962 - Real_acc: 3.8101 - val_loss: 8.8876 - val_Real_acc: 4.7708\n",
      "Epoch 697/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5959 - Real_acc: 3.8821 - val_loss: 8.7430 - val_Real_acc: 4.4092\n",
      "Epoch 698/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6859 - Real_acc: 3.8166 - val_loss: 9.0725 - val_Real_acc: 4.4606\n",
      "Epoch 699/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5045 - Real_acc: 3.7970 - val_loss: 8.8327 - val_Real_acc: 4.4362\n",
      "Epoch 700/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5491 - Real_acc: 3.8364 - val_loss: 8.7885 - val_Real_acc: 4.3966\n",
      "Epoch 701/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5811 - Real_acc: 3.8686 - val_loss: 8.8564 - val_Real_acc: 4.3969\n",
      "Epoch 702/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6108 - Real_acc: 3.8385 - val_loss: 9.0271 - val_Real_acc: 4.4084\n",
      "Epoch 703/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6889 - Real_acc: 3.9571 - val_loss: 8.9502 - val_Real_acc: 4.7899\n",
      "Epoch 704/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.5427 - Real_acc: 3.8671 - val_loss: 8.8161 - val_Real_acc: 4.3999\n",
      "Epoch 705/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4732 - Real_acc: 3.7853 - val_loss: 8.7985 - val_Real_acc: 4.5144\n",
      "Epoch 706/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4270 - Real_acc: 3.7490 - val_loss: 8.7789 - val_Real_acc: 4.6043\n",
      "Epoch 707/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.9328 - Real_acc: 3.8771 - val_loss: 8.7555 - val_Real_acc: 4.5960\n",
      "Epoch 708/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4591 - Real_acc: 3.8149 - val_loss: 8.8011 - val_Real_acc: 4.4175\n",
      "Epoch 709/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4289 - Real_acc: 3.9510 - val_loss: 8.7934 - val_Real_acc: 4.4599\n",
      "Epoch 710/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3669 - Real_acc: 3.8065 - val_loss: 9.3340 - val_Real_acc: 4.5244\n",
      "Epoch 711/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6386 - Real_acc: 3.8863 - val_loss: 8.6976 - val_Real_acc: 4.3707\n",
      "Epoch 712/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4090 - Real_acc: 3.8140 - val_loss: 8.7951 - val_Real_acc: 4.3439\n",
      "Epoch 713/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4225 - Real_acc: 3.7588 - val_loss: 8.8194 - val_Real_acc: 4.4609\n",
      "Epoch 714/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7548 - Real_acc: 3.8437 - val_loss: 8.6658 - val_Real_acc: 4.3180\n",
      "Epoch 715/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3537 - Real_acc: 3.7762 - val_loss: 8.9007 - val_Real_acc: 4.3239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4032 - Real_acc: 3.8731 - val_loss: 8.6089 - val_Real_acc: 4.4179\n",
      "Epoch 717/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3551 - Real_acc: 3.8025 - val_loss: 8.6073 - val_Real_acc: 4.3405\n",
      "Epoch 718/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4421 - Real_acc: 3.8541 - val_loss: 8.9244 - val_Real_acc: 4.4552\n",
      "Epoch 719/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4890 - Real_acc: 3.7830 - val_loss: 8.8641 - val_Real_acc: 4.4062\n",
      "Epoch 720/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3546 - Real_acc: 3.7508 - val_loss: 8.8645 - val_Real_acc: 4.4312\n",
      "Epoch 721/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.7173 - Real_acc: 3.8036 - val_loss: 8.7795 - val_Real_acc: 4.5073\n",
      "Epoch 722/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4050 - Real_acc: 3.8060 - val_loss: 8.6947 - val_Real_acc: 4.7842\n",
      "Epoch 723/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3955 - Real_acc: 3.8899 - val_loss: 8.6504 - val_Real_acc: 4.3896\n",
      "Epoch 724/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4551 - Real_acc: 3.7682 - val_loss: 8.6210 - val_Real_acc: 4.6600\n",
      "Epoch 725/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3341 - Real_acc: 3.8545 - val_loss: 8.6066 - val_Real_acc: 4.3458\n",
      "Epoch 726/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3560 - Real_acc: 3.7657 - val_loss: 8.8255 - val_Real_acc: 4.4985\n",
      "Epoch 727/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3343 - Real_acc: 3.8145 - val_loss: 9.0729 - val_Real_acc: 4.4035\n",
      "Epoch 728/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4773 - Real_acc: 3.7502 - val_loss: 8.6214 - val_Real_acc: 4.3455\n",
      "Epoch 729/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.4019 - Real_acc: 3.8609 - val_loss: 9.0767 - val_Real_acc: 4.5554\n",
      "Epoch 730/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3419 - Real_acc: 3.7643 - val_loss: 8.6713 - val_Real_acc: 4.3589\n",
      "Epoch 731/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3292 - Real_acc: 3.8238 - val_loss: 8.6091 - val_Real_acc: 4.3741\n",
      "Epoch 732/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3989 - Real_acc: 3.8336 - val_loss: 8.5967 - val_Real_acc: 4.3508\n",
      "Epoch 733/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2456 - Real_acc: 3.7195 - val_loss: 8.7323 - val_Real_acc: 4.3869\n",
      "Epoch 734/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2612 - Real_acc: 3.8609 - val_loss: 8.4982 - val_Real_acc: 4.5359\n",
      "Epoch 735/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3630 - Real_acc: 3.8014 - val_loss: 8.6304 - val_Real_acc: 4.8802\n",
      "Epoch 736/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3238 - Real_acc: 3.8228 - val_loss: 8.6892 - val_Real_acc: 4.5085\n",
      "Epoch 737/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3806 - Real_acc: 3.8669 - val_loss: 8.6481 - val_Real_acc: 4.4758\n",
      "Epoch 738/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3706 - Real_acc: 3.8276 - val_loss: 8.5381 - val_Real_acc: 4.3603\n",
      "Epoch 739/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3233 - Real_acc: 3.8445 - val_loss: 8.5788 - val_Real_acc: 4.5315\n",
      "Epoch 740/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3057 - Real_acc: 3.9281 - val_loss: 8.4702 - val_Real_acc: 4.4763\n",
      "Epoch 741/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2427 - Real_acc: 3.9116 - val_loss: 8.4950 - val_Real_acc: 4.2573\n",
      "Epoch 742/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1878 - Real_acc: 3.7428 - val_loss: 8.5024 - val_Real_acc: 4.3142\n",
      "Epoch 743/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2709 - Real_acc: 3.7712 - val_loss: 8.6745 - val_Real_acc: 4.3011\n",
      "Epoch 744/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2268 - Real_acc: 3.7172 - val_loss: 8.4710 - val_Real_acc: 4.4124\n",
      "Epoch 745/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3438 - Real_acc: 3.8376 - val_loss: 8.6397 - val_Real_acc: 4.5620\n",
      "Epoch 746/1000\n",
      "168/168 [==============================] - ETA: 0s - loss: 8.5055 - Real_acc: 3.81 - 1s 4ms/step - loss: 8.4956 - Real_acc: 3.8099 - val_loss: 8.5507 - val_Real_acc: 4.4098\n",
      "Epoch 747/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1755 - Real_acc: 3.7393 - val_loss: 8.4667 - val_Real_acc: 4.4545\n",
      "Epoch 748/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1781 - Real_acc: 3.7830 - val_loss: 8.5892 - val_Real_acc: 4.3584\n",
      "Epoch 749/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2061 - Real_acc: 3.7729 - val_loss: 8.4025 - val_Real_acc: 4.3493\n",
      "Epoch 750/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2886 - Real_acc: 3.8625 - val_loss: 8.5370 - val_Real_acc: 4.3880\n",
      "Epoch 751/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1340 - Real_acc: 3.7802 - val_loss: 8.5681 - val_Real_acc: 4.3996\n",
      "Epoch 752/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1263 - Real_acc: 3.7779 - val_loss: 8.4079 - val_Real_acc: 4.6411\n",
      "Epoch 753/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1444 - Real_acc: 3.8215 - val_loss: 8.3775 - val_Real_acc: 4.3870\n",
      "Epoch 754/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1452 - Real_acc: 3.8658 - val_loss: 8.6686 - val_Real_acc: 4.4186\n",
      "Epoch 755/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3746 - Real_acc: 3.8183 - val_loss: 8.3855 - val_Real_acc: 4.3037\n",
      "Epoch 756/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2067 - Real_acc: 3.7239 - val_loss: 8.7495 - val_Real_acc: 4.4266\n",
      "Epoch 757/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2333 - Real_acc: 3.7485 - val_loss: 8.5370 - val_Real_acc: 4.4136\n",
      "Epoch 758/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1619 - Real_acc: 3.7284 - val_loss: 8.4097 - val_Real_acc: 4.4786\n",
      "Epoch 759/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1572 - Real_acc: 3.7819 - val_loss: 8.3696 - val_Real_acc: 4.2835\n",
      "Epoch 760/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1542 - Real_acc: 3.7986 - val_loss: 8.3658 - val_Real_acc: 4.3679\n",
      "Epoch 761/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1119 - Real_acc: 3.7144 - val_loss: 8.7108 - val_Real_acc: 4.3613\n",
      "Epoch 762/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.3005 - Real_acc: 3.7078 - val_loss: 8.4276 - val_Real_acc: 4.4905\n",
      "Epoch 763/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0469 - Real_acc: 3.6823 - val_loss: 8.3615 - val_Real_acc: 4.3972\n",
      "Epoch 764/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0672 - Real_acc: 3.7657 - val_loss: 8.3605 - val_Real_acc: 4.5495\n",
      "Epoch 765/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0744 - Real_acc: 3.8279 - val_loss: 8.4518 - val_Real_acc: 4.4432\n",
      "Epoch 766/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0775 - Real_acc: 3.7421 - val_loss: 8.6226 - val_Real_acc: 4.6895\n",
      "Epoch 767/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1436 - Real_acc: 3.7559 - val_loss: 8.4034 - val_Real_acc: 4.3525\n",
      "Epoch 768/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1504 - Real_acc: 3.8206 - val_loss: 8.4942 - val_Real_acc: 4.4563\n",
      "Epoch 769/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1247 - Real_acc: 3.8818 - val_loss: 8.4298 - val_Real_acc: 4.3574\n",
      "Epoch 770/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0808 - Real_acc: 3.7087 - val_loss: 8.3973 - val_Real_acc: 4.3814\n",
      "Epoch 771/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.2481 - Real_acc: 3.8411 - val_loss: 8.3388 - val_Real_acc: 4.3569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1675 - Real_acc: 3.8396 - val_loss: 8.3804 - val_Real_acc: 4.3614\n",
      "Epoch 773/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0396 - Real_acc: 3.7570 - val_loss: 8.2731 - val_Real_acc: 4.4280\n",
      "Epoch 774/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0232 - Real_acc: 3.8409 - val_loss: 8.3210 - val_Real_acc: 4.5536\n",
      "Epoch 775/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0351 - Real_acc: 3.7636 - val_loss: 8.3182 - val_Real_acc: 4.4105\n",
      "Epoch 776/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0769 - Real_acc: 3.7761 - val_loss: 8.2174 - val_Real_acc: 4.2358\n",
      "Epoch 777/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9941 - Real_acc: 3.7403 - val_loss: 8.4462 - val_Real_acc: 4.4704\n",
      "Epoch 778/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.6894 - Real_acc: 3.8000 - val_loss: 8.6455 - val_Real_acc: 4.3857\n",
      "Epoch 779/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0366 - Real_acc: 3.7212 - val_loss: 8.4503 - val_Real_acc: 4.4391\n",
      "Epoch 780/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0252 - Real_acc: 3.7727 - val_loss: 8.4705 - val_Real_acc: 4.3202\n",
      "Epoch 781/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0428 - Real_acc: 3.7758 - val_loss: 8.1967 - val_Real_acc: 4.2324\n",
      "Epoch 782/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9376 - Real_acc: 3.7205 - val_loss: 8.2818 - val_Real_acc: 4.5182\n",
      "Epoch 783/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0495 - Real_acc: 3.7199 - val_loss: 8.3314 - val_Real_acc: 4.3436\n",
      "Epoch 784/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0329 - Real_acc: 3.7556 - val_loss: 8.3765 - val_Real_acc: 4.2874\n",
      "Epoch 785/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1824 - Real_acc: 3.7964 - val_loss: 8.1406 - val_Real_acc: 4.3509\n",
      "Epoch 786/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9078 - Real_acc: 3.7309 - val_loss: 8.3506 - val_Real_acc: 4.2676\n",
      "Epoch 787/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9879 - Real_acc: 3.6958 - val_loss: 8.2284 - val_Real_acc: 4.6104\n",
      "Epoch 788/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.1320 - Real_acc: 3.7283 - val_loss: 8.1921 - val_Real_acc: 4.5638\n",
      "Epoch 789/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8948 - Real_acc: 3.9033 - val_loss: 8.2682 - val_Real_acc: 4.4493\n",
      "Epoch 790/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9186 - Real_acc: 3.8018 - val_loss: 8.2507 - val_Real_acc: 4.4431\n",
      "Epoch 791/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8897 - Real_acc: 3.6638 - val_loss: 8.1322 - val_Real_acc: 4.3325\n",
      "Epoch 792/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9414 - Real_acc: 3.7837 - val_loss: 8.2500 - val_Real_acc: 4.5194\n",
      "Epoch 793/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9740 - Real_acc: 3.7465 - val_loss: 8.2673 - val_Real_acc: 4.3759\n",
      "Epoch 794/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9379 - Real_acc: 3.6727 - val_loss: 8.1863 - val_Real_acc: 4.2977\n",
      "Epoch 795/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9596 - Real_acc: 3.6970 - val_loss: 8.1875 - val_Real_acc: 4.2970\n",
      "Epoch 796/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8533 - Real_acc: 3.6684 - val_loss: 8.6965 - val_Real_acc: 4.4281\n",
      "Epoch 797/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 8.0366 - Real_acc: 3.7448 - val_loss: 8.3025 - val_Real_acc: 4.3093\n",
      "Epoch 798/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9531 - Real_acc: 3.7817 - val_loss: 8.2098 - val_Real_acc: 4.3756\n",
      "Epoch 799/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8499 - Real_acc: 3.6790 - val_loss: 8.1512 - val_Real_acc: 4.2645\n",
      "Epoch 800/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8815 - Real_acc: 3.7092 - val_loss: 8.3544 - val_Real_acc: 4.6407\n",
      "Epoch 801/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8422 - Real_acc: 3.7577 - val_loss: 8.1794 - val_Real_acc: 4.2149\n",
      "Epoch 802/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8636 - Real_acc: 3.7621 - val_loss: 8.1223 - val_Real_acc: 4.3277\n",
      "Epoch 803/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9898 - Real_acc: 3.8330 - val_loss: 8.2688 - val_Real_acc: 4.2319\n",
      "Epoch 804/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8892 - Real_acc: 3.7033 - val_loss: 8.1736 - val_Real_acc: 4.2635\n",
      "Epoch 805/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.9014 - Real_acc: 3.7216 - val_loss: 8.0973 - val_Real_acc: 4.3545\n",
      "Epoch 806/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8800 - Real_acc: 3.6528 - val_loss: 8.0907 - val_Real_acc: 4.2547\n",
      "Epoch 807/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7432 - Real_acc: 3.6864 - val_loss: 8.7624 - val_Real_acc: 4.4138\n",
      "Epoch 808/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8109 - Real_acc: 3.6286 - val_loss: 8.3818 - val_Real_acc: 4.3641\n",
      "Epoch 809/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8398 - Real_acc: 3.7864 - val_loss: 8.1530 - val_Real_acc: 4.2458\n",
      "Epoch 810/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8151 - Real_acc: 3.8247 - val_loss: 8.0623 - val_Real_acc: 4.5956\n",
      "Epoch 811/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7259 - Real_acc: 3.6554 - val_loss: 8.0828 - val_Real_acc: 4.5265\n",
      "Epoch 812/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8897 - Real_acc: 3.8040 - val_loss: 8.9613 - val_Real_acc: 4.3379\n",
      "Epoch 813/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8339 - Real_acc: 3.7678 - val_loss: 8.2283 - val_Real_acc: 4.4584\n",
      "Epoch 814/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7453 - Real_acc: 3.7781 - val_loss: 8.0546 - val_Real_acc: 4.2010\n",
      "Epoch 815/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8842 - Real_acc: 3.7634 - val_loss: 8.0537 - val_Real_acc: 4.3801\n",
      "Epoch 816/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8636 - Real_acc: 3.6830 - val_loss: 8.0266 - val_Real_acc: 4.2406\n",
      "Epoch 817/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7440 - Real_acc: 3.6805 - val_loss: 8.1353 - val_Real_acc: 4.4317\n",
      "Epoch 818/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7742 - Real_acc: 3.6771 - val_loss: 8.3324 - val_Real_acc: 4.2220\n",
      "Epoch 819/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7453 - Real_acc: 3.6649 - val_loss: 7.9961 - val_Real_acc: 4.1923\n",
      "Epoch 820/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7725 - Real_acc: 3.6283 - val_loss: 8.1849 - val_Real_acc: 4.3992\n",
      "Epoch 821/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7132 - Real_acc: 3.7276 - val_loss: 8.1251 - val_Real_acc: 4.2646\n",
      "Epoch 822/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7449 - Real_acc: 3.7499 - val_loss: 8.0079 - val_Real_acc: 4.2562\n",
      "Epoch 823/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8721 - Real_acc: 3.7279 - val_loss: 7.9537 - val_Real_acc: 4.2269\n",
      "Epoch 824/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7235 - Real_acc: 3.6618 - val_loss: 8.1038 - val_Real_acc: 4.1377\n",
      "Epoch 825/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7219 - Real_acc: 3.6435 - val_loss: 8.0261 - val_Real_acc: 4.3801\n",
      "Epoch 826/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7127 - Real_acc: 3.7454 - val_loss: 7.9791 - val_Real_acc: 4.3105\n",
      "Epoch 827/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6787 - Real_acc: 3.7618 - val_loss: 7.9264 - val_Real_acc: 4.2448\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6948 - Real_acc: 3.6573 - val_loss: 7.9763 - val_Real_acc: 4.1897\n",
      "Epoch 829/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6877 - Real_acc: 3.6872 - val_loss: 7.9597 - val_Real_acc: 4.2451\n",
      "Epoch 830/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6592 - Real_acc: 3.6588 - val_loss: 8.3071 - val_Real_acc: 4.4977\n",
      "Epoch 831/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7998 - Real_acc: 3.8061 - val_loss: 7.9510 - val_Real_acc: 4.4947\n",
      "Epoch 832/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6108 - Real_acc: 3.5924 - val_loss: 8.1073 - val_Real_acc: 4.7697\n",
      "Epoch 833/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.8151 - Real_acc: 3.6942 - val_loss: 7.9138 - val_Real_acc: 4.2748\n",
      "Epoch 834/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.6340 - Real_acc: 3.6940 - val_loss: 8.2932 - val_Real_acc: 4.7573\n",
      "Epoch 835/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.7864 - Real_acc: 3.7705 - val_loss: 8.2602 - val_Real_acc: 4.2194\n",
      "Epoch 836/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.9409 - Real_acc: 3.6391 - val_loss: 8.0710 - val_Real_acc: 4.3404\n",
      "Epoch 837/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6627 - Real_acc: 3.6890 - val_loss: 8.1475 - val_Real_acc: 4.2790\n",
      "Epoch 838/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.6335 - Real_acc: 3.6976 - val_loss: 7.9741 - val_Real_acc: 4.1830\n",
      "Epoch 839/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6047 - Real_acc: 3.6334 - val_loss: 8.1153 - val_Real_acc: 4.2086\n",
      "Epoch 840/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7188 - Real_acc: 3.7126 - val_loss: 8.0324 - val_Real_acc: 4.3154\n",
      "Epoch 841/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.6608 - Real_acc: 3.7441 - val_loss: 7.9045 - val_Real_acc: 4.2380\n",
      "Epoch 842/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6320 - Real_acc: 3.6999 - val_loss: 8.0026 - val_Real_acc: 4.2076\n",
      "Epoch 843/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5732 - Real_acc: 3.7094 - val_loss: 7.9814 - val_Real_acc: 4.3600\n",
      "Epoch 844/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.5669 - Real_acc: 3.6692 - val_loss: 7.9394 - val_Real_acc: 4.1945\n",
      "Epoch 845/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5935 - Real_acc: 3.6296 - val_loss: 7.8280 - val_Real_acc: 4.3151\n",
      "Epoch 846/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5895 - Real_acc: 3.6965 - val_loss: 7.8754 - val_Real_acc: 4.2202\n",
      "Epoch 847/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5496 - Real_acc: 3.6615 - val_loss: 7.8738 - val_Real_acc: 4.2000\n",
      "Epoch 848/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5539 - Real_acc: 3.6451 - val_loss: 7.9129 - val_Real_acc: 4.3955\n",
      "Epoch 849/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5572 - Real_acc: 3.7121 - val_loss: 8.1891 - val_Real_acc: 4.4511\n",
      "Epoch 850/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6558 - Real_acc: 3.6988 - val_loss: 7.8455 - val_Real_acc: 4.3301\n",
      "Epoch 851/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5345 - Real_acc: 3.6786 - val_loss: 7.8834 - val_Real_acc: 4.3071\n",
      "Epoch 852/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5592 - Real_acc: 3.7454 - val_loss: 7.8482 - val_Real_acc: 4.1163\n",
      "Epoch 853/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5452 - Real_acc: 3.6186 - val_loss: 7.8318 - val_Real_acc: 4.3266\n",
      "Epoch 854/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6151 - Real_acc: 3.6111 - val_loss: 7.8153 - val_Real_acc: 4.1327\n",
      "Epoch 855/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6266 - Real_acc: 3.6149 - val_loss: 7.7910 - val_Real_acc: 4.1689\n",
      "Epoch 856/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5091 - Real_acc: 3.6067 - val_loss: 7.9259 - val_Real_acc: 4.3233\n",
      "Epoch 857/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4834 - Real_acc: 3.6061 - val_loss: 7.8496 - val_Real_acc: 4.1578\n",
      "Epoch 858/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5294 - Real_acc: 3.7445 - val_loss: 7.8438 - val_Real_acc: 4.3389\n",
      "Epoch 859/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5337 - Real_acc: 3.7145 - val_loss: 8.1139 - val_Real_acc: 4.3848\n",
      "Epoch 860/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5050 - Real_acc: 3.6223 - val_loss: 7.9981 - val_Real_acc: 4.2427\n",
      "Epoch 861/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4992 - Real_acc: 3.6805 - val_loss: 7.7134 - val_Real_acc: 4.2415\n",
      "Epoch 862/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4567 - Real_acc: 3.6518 - val_loss: 7.7873 - val_Real_acc: 4.3311\n",
      "Epoch 863/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4197 - Real_acc: 3.6501 - val_loss: 7.7356 - val_Real_acc: 4.2063\n",
      "Epoch 864/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4446 - Real_acc: 3.6043 - val_loss: 7.8576 - val_Real_acc: 4.1992\n",
      "Epoch 865/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.7156 - Real_acc: 3.8057 - val_loss: 7.9121 - val_Real_acc: 4.3857\n",
      "Epoch 866/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4471 - Real_acc: 3.6411 - val_loss: 7.6964 - val_Real_acc: 4.2132\n",
      "Epoch 867/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4713 - Real_acc: 3.6401 - val_loss: 7.8407 - val_Real_acc: 4.1426\n",
      "Epoch 868/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4726 - Real_acc: 3.5746 - val_loss: 7.9597 - val_Real_acc: 4.2943\n",
      "Epoch 869/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.5184 - Real_acc: 3.7231 - val_loss: 7.8796 - val_Real_acc: 4.2014\n",
      "Epoch 870/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4104 - Real_acc: 3.5897 - val_loss: 7.7038 - val_Real_acc: 4.2245\n",
      "Epoch 871/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4585 - Real_acc: 3.6642 - val_loss: 7.8961 - val_Real_acc: 4.1647\n",
      "Epoch 872/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6519 - Real_acc: 3.6281 - val_loss: 7.7070 - val_Real_acc: 4.0741\n",
      "Epoch 873/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.5297 - Real_acc: 3.6763 - val_loss: 7.7178 - val_Real_acc: 4.2674\n",
      "Epoch 874/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4250 - Real_acc: 3.6218 - val_loss: 7.6709 - val_Real_acc: 4.2768\n",
      "Epoch 875/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3972 - Real_acc: 3.5852 - val_loss: 7.6679 - val_Real_acc: 4.1612\n",
      "Epoch 876/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3864 - Real_acc: 3.6481 - val_loss: 7.6989 - val_Real_acc: 4.1916\n",
      "Epoch 877/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3616 - Real_acc: 3.6779 - val_loss: 8.0334 - val_Real_acc: 4.2490\n",
      "Epoch 878/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3825 - Real_acc: 3.6363 - val_loss: 7.6837 - val_Real_acc: 4.1602\n",
      "Epoch 879/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3891 - Real_acc: 3.7633 - val_loss: 7.5836 - val_Real_acc: 4.1133\n",
      "Epoch 880/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3729 - Real_acc: 3.5653 - val_loss: 7.9089 - val_Real_acc: 4.4304\n",
      "Epoch 881/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4688 - Real_acc: 3.6613 - val_loss: 7.6922 - val_Real_acc: 4.3740\n",
      "Epoch 882/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3897 - Real_acc: 3.6674 - val_loss: 7.6439 - val_Real_acc: 4.2269\n",
      "Epoch 883/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3865 - Real_acc: 3.6179 - val_loss: 7.7645 - val_Real_acc: 4.1863\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4075 - Real_acc: 3.6646 - val_loss: 7.9232 - val_Real_acc: 4.2219\n",
      "Epoch 885/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4167 - Real_acc: 3.6068 - val_loss: 8.1452 - val_Real_acc: 4.2921\n",
      "Epoch 886/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4382 - Real_acc: 3.6542 - val_loss: 7.7280 - val_Real_acc: 4.1626\n",
      "Epoch 887/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3343 - Real_acc: 3.6518 - val_loss: 7.5820 - val_Real_acc: 4.2046\n",
      "Epoch 888/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4128 - Real_acc: 3.6455 - val_loss: 7.6606 - val_Real_acc: 4.3485\n",
      "Epoch 889/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3203 - Real_acc: 3.6514 - val_loss: 7.5354 - val_Real_acc: 4.0764\n",
      "Epoch 890/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3197 - Real_acc: 3.5818 - val_loss: 7.6073 - val_Real_acc: 4.1998\n",
      "Epoch 891/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3123 - Real_acc: 3.6648 - val_loss: 7.6423 - val_Real_acc: 4.1880\n",
      "Epoch 892/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2847 - Real_acc: 3.6285 - val_loss: 7.5202 - val_Real_acc: 4.1004\n",
      "Epoch 893/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2627 - Real_acc: 3.6125 - val_loss: 7.8083 - val_Real_acc: 4.1431\n",
      "Epoch 894/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3061 - Real_acc: 3.5378 - val_loss: 7.5744 - val_Real_acc: 4.7518\n",
      "Epoch 895/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3057 - Real_acc: 3.6145 - val_loss: 7.6556 - val_Real_acc: 4.2085\n",
      "Epoch 896/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3103 - Real_acc: 3.6398 - val_loss: 7.8727 - val_Real_acc: 4.1600\n",
      "Epoch 897/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2859 - Real_acc: 3.6476 - val_loss: 7.6769 - val_Real_acc: 4.5846\n",
      "Epoch 898/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3257 - Real_acc: 3.6628 - val_loss: 7.6106 - val_Real_acc: 4.1813\n",
      "Epoch 899/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3952 - Real_acc: 3.6724 - val_loss: 7.6848 - val_Real_acc: 4.2781\n",
      "Epoch 900/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2210 - Real_acc: 3.6520 - val_loss: 7.9948 - val_Real_acc: 4.3055\n",
      "Epoch 901/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2839 - Real_acc: 3.6146 - val_loss: 8.4042 - val_Real_acc: 4.4310\n",
      "Epoch 902/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2994 - Real_acc: 3.6380 - val_loss: 7.6126 - val_Real_acc: 4.1180\n",
      "Epoch 903/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2716 - Real_acc: 3.6145 - val_loss: 7.6903 - val_Real_acc: 4.4027\n",
      "Epoch 904/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2363 - Real_acc: 3.6708 - val_loss: 7.5164 - val_Real_acc: 4.1974\n",
      "Epoch 905/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2607 - Real_acc: 3.6472 - val_loss: 7.5209 - val_Real_acc: 4.1276\n",
      "Epoch 906/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.3415 - Real_acc: 3.6230 - val_loss: 7.5070 - val_Real_acc: 4.0687\n",
      "Epoch 907/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2360 - Real_acc: 3.6521 - val_loss: 7.5907 - val_Real_acc: 4.3696\n",
      "Epoch 908/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2126 - Real_acc: 3.5613 - val_loss: 7.5062 - val_Real_acc: 4.3290\n",
      "Epoch 909/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2347 - Real_acc: 3.5952 - val_loss: 7.6061 - val_Real_acc: 4.2190\n",
      "Epoch 910/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2323 - Real_acc: 3.5589 - val_loss: 7.5516 - val_Real_acc: 4.1959\n",
      "Epoch 911/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1889 - Real_acc: 3.5959 - val_loss: 7.5840 - val_Real_acc: 4.2280\n",
      "Epoch 912/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2007 - Real_acc: 3.6060 - val_loss: 7.5341 - val_Real_acc: 4.3317\n",
      "Epoch 913/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2120 - Real_acc: 3.5915 - val_loss: 7.5018 - val_Real_acc: 4.3246\n",
      "Epoch 914/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1855 - Real_acc: 3.6721 - val_loss: 7.4803 - val_Real_acc: 4.1706\n",
      "Epoch 915/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1560 - Real_acc: 3.5508 - val_loss: 7.4909 - val_Real_acc: 4.1030\n",
      "Epoch 916/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1583 - Real_acc: 3.6171 - val_loss: 7.5542 - val_Real_acc: 4.1831\n",
      "Epoch 917/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.4156 - Real_acc: 3.6338 - val_loss: 7.6134 - val_Real_acc: 4.2169\n",
      "Epoch 918/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2035 - Real_acc: 3.6578 - val_loss: 7.5643 - val_Real_acc: 4.0500\n",
      "Epoch 919/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2501 - Real_acc: 3.5534 - val_loss: 7.7144 - val_Real_acc: 4.4794\n",
      "Epoch 920/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1671 - Real_acc: 3.6058 - val_loss: 7.3967 - val_Real_acc: 4.0934\n",
      "Epoch 921/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1007 - Real_acc: 3.5505 - val_loss: 7.5708 - val_Real_acc: 4.3833\n",
      "Epoch 922/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1116 - Real_acc: 3.6186 - val_loss: 7.6535 - val_Real_acc: 4.1464\n",
      "Epoch 923/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1471 - Real_acc: 3.5650 - val_loss: 7.4374 - val_Real_acc: 4.1917\n",
      "Epoch 924/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1196 - Real_acc: 3.5859 - val_loss: 7.3840 - val_Real_acc: 4.1577\n",
      "Epoch 925/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1827 - Real_acc: 3.6628 - val_loss: 7.4247 - val_Real_acc: 4.0831\n",
      "Epoch 926/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1342 - Real_acc: 3.5311 - val_loss: 7.5013 - val_Real_acc: 4.1575\n",
      "Epoch 927/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2023 - Real_acc: 3.6562 - val_loss: 7.5040 - val_Real_acc: 4.1140\n",
      "Epoch 928/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1437 - Real_acc: 3.5836 - val_loss: 7.5265 - val_Real_acc: 4.1491\n",
      "Epoch 929/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1733 - Real_acc: 3.5665 - val_loss: 7.4033 - val_Real_acc: 4.0930\n",
      "Epoch 930/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0970 - Real_acc: 3.5609 - val_loss: 7.5430 - val_Real_acc: 4.1540\n",
      "Epoch 931/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1067 - Real_acc: 3.5527 - val_loss: 7.4639 - val_Real_acc: 4.3362\n",
      "Epoch 932/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0956 - Real_acc: 3.5468 - val_loss: 7.3856 - val_Real_acc: 4.0909\n",
      "Epoch 933/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1641 - Real_acc: 3.5428 - val_loss: 7.4292 - val_Real_acc: 4.1831\n",
      "Epoch 934/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1088 - Real_acc: 3.5578 - val_loss: 7.4525 - val_Real_acc: 4.3535\n",
      "Epoch 935/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0661 - Real_acc: 3.5249 - val_loss: 7.6183 - val_Real_acc: 4.2248\n",
      "Epoch 936/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1153 - Real_acc: 3.5596 - val_loss: 7.3421 - val_Real_acc: 4.4665\n",
      "Epoch 937/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0624 - Real_acc: 3.5768 - val_loss: 7.3145 - val_Real_acc: 4.0471\n",
      "Epoch 938/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0825 - Real_acc: 3.5425 - val_loss: 7.3041 - val_Real_acc: 4.1421\n",
      "Epoch 939/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0064 - Real_acc: 3.5891 - val_loss: 7.3096 - val_Real_acc: 4.4566\n",
      "Epoch 940/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 7.2446 - Real_acc: 3.5504 - val_loss: 7.3764 - val_Real_acc: 4.4105\n",
      "Epoch 941/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0559 - Real_acc: 3.5896 - val_loss: 7.3000 - val_Real_acc: 4.0154\n",
      "Epoch 942/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0447 - Real_acc: 3.5530 - val_loss: 7.3145 - val_Real_acc: 4.1007\n",
      "Epoch 943/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0111 - Real_acc: 3.5803 - val_loss: 7.5383 - val_Real_acc: 4.1534\n",
      "Epoch 944/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0159 - Real_acc: 3.5310 - val_loss: 7.3359 - val_Real_acc: 4.2220\n",
      "Epoch 945/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9795 - Real_acc: 3.6069 - val_loss: 7.3251 - val_Real_acc: 4.0881\n",
      "Epoch 946/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0421 - Real_acc: 3.5124 - val_loss: 7.2858 - val_Real_acc: 4.1026\n",
      "Epoch 947/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0130 - Real_acc: 3.5393 - val_loss: 7.2727 - val_Real_acc: 4.1035\n",
      "Epoch 948/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9991 - Real_acc: 3.5646 - val_loss: 7.7352 - val_Real_acc: 4.3282\n",
      "Epoch 949/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1431 - Real_acc: 3.6206 - val_loss: 7.3363 - val_Real_acc: 4.1832\n",
      "Epoch 950/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9983 - Real_acc: 3.5613 - val_loss: 7.5813 - val_Real_acc: 4.1067\n",
      "Epoch 951/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.1660 - Real_acc: 3.6069 - val_loss: 7.3531 - val_Real_acc: 4.4640\n",
      "Epoch 952/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.0062 - Real_acc: 3.5865 - val_loss: 7.3405 - val_Real_acc: 4.1459\n",
      "Epoch 953/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9701 - Real_acc: 3.5364 - val_loss: 7.3114 - val_Real_acc: 4.0486\n",
      "Epoch 954/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9530 - Real_acc: 3.5637 - val_loss: 7.3091 - val_Real_acc: 4.0309\n",
      "Epoch 955/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9622 - Real_acc: 3.6101 - val_loss: 7.2456 - val_Real_acc: 4.2055\n",
      "Epoch 956/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9602 - Real_acc: 3.5583 - val_loss: 7.2806 - val_Real_acc: 4.0610\n",
      "Epoch 957/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9644 - Real_acc: 3.5301 - val_loss: 7.3848 - val_Real_acc: 3.9996\n",
      "Epoch 958/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9597 - Real_acc: 3.4985 - val_loss: 7.3239 - val_Real_acc: 4.0562\n",
      "Epoch 959/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9205 - Real_acc: 3.5463 - val_loss: 7.1681 - val_Real_acc: 4.2440\n",
      "Epoch 960/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.0444 - Real_acc: 3.6864 - val_loss: 7.1832 - val_Real_acc: 4.1501\n",
      "Epoch 961/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9172 - Real_acc: 3.5179 - val_loss: 7.3596 - val_Real_acc: 4.2644\n",
      "Epoch 962/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8911 - Real_acc: 3.5556 - val_loss: 7.3039 - val_Real_acc: 4.0994\n",
      "Epoch 963/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9953 - Real_acc: 3.5751 - val_loss: 7.3130 - val_Real_acc: 4.1940\n",
      "Epoch 964/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 7.6116 - Real_acc: 3.6079 - val_loss: 7.2844 - val_Real_acc: 4.1095\n",
      "Epoch 965/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8482 - Real_acc: 3.5004 - val_loss: 7.3560 - val_Real_acc: 4.4334\n",
      "Epoch 966/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9008 - Real_acc: 3.6061 - val_loss: 7.2551 - val_Real_acc: 4.1188\n",
      "Epoch 967/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8583 - Real_acc: 3.5853 - val_loss: 7.1903 - val_Real_acc: 4.2275\n",
      "Epoch 968/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8483 - Real_acc: 3.6461 - val_loss: 7.1974 - val_Real_acc: 4.0183\n",
      "Epoch 969/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8414 - Real_acc: 3.4719 - val_loss: 7.5225 - val_Real_acc: 4.2091\n",
      "Epoch 970/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8686 - Real_acc: 3.5487 - val_loss: 7.1613 - val_Real_acc: 4.0095\n",
      "Epoch 971/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8465 - Real_acc: 3.4401 - val_loss: 7.1438 - val_Real_acc: 4.1112\n",
      "Epoch 972/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8611 - Real_acc: 3.5228 - val_loss: 7.1822 - val_Real_acc: 3.9705\n",
      "Epoch 973/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8572 - Real_acc: 3.4900 - val_loss: 7.1393 - val_Real_acc: 4.1727\n",
      "Epoch 974/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8863 - Real_acc: 3.4958 - val_loss: 7.2818 - val_Real_acc: 4.0966\n",
      "Epoch 975/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8434 - Real_acc: 3.4595 - val_loss: 7.2541 - val_Real_acc: 4.0991\n",
      "Epoch 976/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8336 - Real_acc: 3.4860 - val_loss: 7.3547 - val_Real_acc: 4.0800\n",
      "Epoch 977/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9010 - Real_acc: 3.5054 - val_loss: 7.1511 - val_Real_acc: 4.0791\n",
      "Epoch 978/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8419 - Real_acc: 3.5538 - val_loss: 7.1571 - val_Real_acc: 3.9398\n",
      "Epoch 979/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8385 - Real_acc: 3.4373 - val_loss: 7.1089 - val_Real_acc: 4.0726\n",
      "Epoch 980/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8548 - Real_acc: 3.4860 - val_loss: 7.0939 - val_Real_acc: 4.0284\n",
      "Epoch 981/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9057 - Real_acc: 3.5285 - val_loss: 7.3120 - val_Real_acc: 4.0460\n",
      "Epoch 982/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.9073 - Real_acc: 3.4687 - val_loss: 7.1613 - val_Real_acc: 4.0069\n",
      "Epoch 983/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8425 - Real_acc: 3.5931 - val_loss: 7.1167 - val_Real_acc: 3.9996\n",
      "Epoch 984/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8342 - Real_acc: 3.4824 - val_loss: 7.1085 - val_Real_acc: 4.1715\n",
      "Epoch 985/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8187 - Real_acc: 3.4639 - val_loss: 7.1710 - val_Real_acc: 3.9413\n",
      "Epoch 986/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8429 - Real_acc: 3.4622 - val_loss: 7.1863 - val_Real_acc: 4.2400\n",
      "Epoch 987/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8148 - Real_acc: 3.4507 - val_loss: 7.1138 - val_Real_acc: 3.8873\n",
      "Epoch 988/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7841 - Real_acc: 3.4908 - val_loss: 7.1110 - val_Real_acc: 3.9749\n",
      "Epoch 989/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8346 - Real_acc: 3.5784 - val_loss: 7.1741 - val_Real_acc: 3.9731\n",
      "Epoch 990/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8231 - Real_acc: 3.4875 - val_loss: 7.0433 - val_Real_acc: 3.9467\n",
      "Epoch 991/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7719 - Real_acc: 3.4969 - val_loss: 7.0742 - val_Real_acc: 3.9253\n",
      "Epoch 992/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8897 - Real_acc: 3.4427 - val_loss: 7.9222 - val_Real_acc: 4.1821\n",
      "Epoch 993/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8893 - Real_acc: 3.4901 - val_loss: 7.0774 - val_Real_acc: 3.8982\n",
      "Epoch 994/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7693 - Real_acc: 3.4662 - val_loss: 7.1894 - val_Real_acc: 4.2751\n",
      "Epoch 995/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7792 - Real_acc: 3.4236 - val_loss: 7.1274 - val_Real_acc: 4.0357\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7742 - Real_acc: 3.4203 - val_loss: 7.2278 - val_Real_acc: 4.1226\n",
      "Epoch 997/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7493 - Real_acc: 3.5259 - val_loss: 7.0715 - val_Real_acc: 3.9579\n",
      "Epoch 998/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7832 - Real_acc: 3.4554 - val_loss: 7.1665 - val_Real_acc: 4.1119\n",
      "Epoch 999/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.7221 - Real_acc: 3.4879 - val_loss: 7.4995 - val_Real_acc: 4.2427\n",
      "Epoch 1000/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 6.8117 - Real_acc: 3.4812 - val_loss: 7.2339 - val_Real_acc: 4.0566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27592aba8d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_robust_scaled, Y_train, epochs=1000, validation_split=0.1, shuffle=True, verbose=1,  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_robust_scaled, Y_train, epochs=2000, shuffle=True, verbose=1)\n",
    "scores = []\n",
    "i=1\n",
    "for train_index, val_index in KFold(9).split(x_robust_scaled):\n",
    "    x_train,x_val=x_robust_scaled[train_index],x_robust_scaled[val_index]\n",
    "    y_train,y_val=Y_train[train_index],Y_train[val_index]\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=1000, shuffle=True, verbose=1, validation_data = (x_val, y_val), batch_size=10)\n",
    "    #test_set = pca.fit_transform(robust_scaler.transform(X_test))\n",
    "    test_set = pca.fit_transform(robust_scaler.transform(X_test))\n",
    "    test_set = test_set.reshape((int(len(test_set)),1,3))\n",
    "    scores.append(list(model.evaluate(test_set,Y_test, batch_size = 10, verbose=0)))\n",
    "    model.save_weights(\"sintering_learning_\"+str(i)+\".h5\")\n",
    "    print(scores[i-1])\n",
    "    i += 1                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(scores)\n",
    "scores[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.argmin(scores[:,1])\n",
    "print(k+1)\n",
    "model.load_weights('sintering_learning_'+str(k+1)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = pca.fit_transform(robust_scaler.transform(X))\n",
    "x_all = x_all.reshape(int(len(x_all)),1,3)\n",
    "data1 = model.predict(x_all)\n",
    "print(data1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29.502674    62.885525     1.8196684 ]\n",
      " [ 33.60846     32.139393     0.93674123]\n",
      " [ 38.304844    36.27403      0.93923676]\n",
      " [ 47.23855     43.5709       0.90277755]\n",
      " [ 42.99855     40.019703     0.9093679 ]\n",
      " [ 43.826508    40.73848      0.9104241 ]\n",
      " [ 61.092697    56.957726     0.9063567 ]\n",
      " [ 87.5874     105.79027      1.2277006 ]\n",
      " [ 74.44969    115.90377      1.4012398 ]\n",
      " [121.99402    114.29047      0.83337533]\n",
      " [137.37254    129.13033      0.825004  ]\n",
      " [176.95222    166.37488      0.77241075]\n",
      " [ 65.63665     97.14377      1.4513577 ]\n",
      " [ 35.57905    200.32944      8.882173  ]\n",
      " [ 73.39276    112.70007      1.6806592 ]\n",
      " [ 36.824722   220.0149      10.180797  ]\n",
      " [ 42.70346    245.65295     10.668107  ]\n",
      " [ 46.392822   262.36633     10.973883  ]\n",
      " [ 27.752453   124.52691      4.9061213 ]\n",
      " [ 34.9389     121.83908      3.7903733 ]\n",
      " [ 46.01081    123.636734     3.1735735 ]\n",
      " [ 57.674896   126.814606     2.6273885 ]\n",
      " [ 97.37465    151.45331      1.5232271 ]\n",
      " [ 85.92523    161.67517      2.3018746 ]\n",
      " [ 73.76543    168.11542      3.2218156 ]\n",
      " [ 55.38881    171.11438      4.3698373 ]\n",
      " [ 43.47228    177.0965       5.2778654 ]\n",
      " [ 39.414085   186.08331      6.4839377 ]\n",
      " [ 37.98857    192.53111      7.343615  ]\n",
      " [ 33.92888    195.29053      8.610127  ]\n",
      " [ 38.810635   220.66893      9.193595  ]\n",
      " [ 87.604324   250.45688      5.3790107 ]\n",
      " [126.72678    264.54767      3.6963992 ]\n",
      " [114.17981    285.83734      5.1645436 ]\n",
      " [ 86.48534    303.76865      7.287884  ]\n",
      " [ 71.72701    310.68475      8.375898  ]\n",
      " [ 60.661827   310.5318      10.462994  ]\n",
      " [ 67.15286    326.4236      10.012055  ]]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_excel(r'dddd.xlsx', sheet_name='Sheet1')\n",
    "df2 = df2.dropna()\n",
    "test_input = pd.DataFrame(df2, columns=['총전류','60V','120V','임팩터'])\n",
    "test_target=pd.DataFrame(df2,columns=['전기이동도 입경','공기역학적 입경','밀도'])\n",
    "test_input = np.array(test_input)\n",
    "test_target=np.array(test_target)\n",
    "test_input = pca.fit_transform(robust_scaler.transform(test_input))\n",
    "test_input = test_input.reshape(int(len(test_input)),1,3)\n",
    "\n",
    "\n",
    "data_test = model.predict(test_input)\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame(data_test, columns=['d_em_pred','d_am_pred', 'Density_pred'])\n",
    "Real = pd.DataFrame(test_target, columns=['d_em','d_am', 'Density' ])\n",
    "Result3 = pd.concat([Pred, Real], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result3.to_csv('./Result_test.csv',float_format='%.3f',sep=',', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pca.fit_transform(robust_scaler.transform(X_test))\n",
    "test_set = test_set.reshape((int(len(test_set)),1,3))\n",
    "score= list(model.evaluate(test_set,Y_test, batch_size = 5, verbose=0))\n",
    "X_test_robust1 = pca.fit_transform(robust_scaler.transform(X_test))\n",
    "X_test_robust1 = X_test_robust1.reshape((int(len(X_test_robust1)),1,3))\n",
    "data2 = model.predict(X_test_robust1)\n",
    "print(score)\n",
    "print(data2)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame(data1, columns=['d_em_pred','d_am_pred', 'Density_pred'])\n",
    "Real = pd.DataFrame(Y, columns=['d_em','d_am', 'Density' ])\n",
    "Result = pd.concat([Pred, Real], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame(data2, columns=['d_em_pred','d_am_pred', 'Density_pred'])\n",
    "Real = pd.DataFrame(Y_test, columns=['d_em','d_am', 'Density' ])\n",
    "Result1 = pd.concat([Pred, Real], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv('./Result_sintering1_all.csv',float_format='%.3f',sep=',', na_rep='NaN')\n",
    "Result1.to_csv('./Result_sintering1_test.csv',float_format='%.3f',sep=',', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"sintering_learning_noNtot.h5\")\n",
    "model.save('Sintering_model_noNtot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = pd.DataFrame(df, columns=['수농도'])\n",
    "Data = np.append(X,data1, axis=1)\n",
    "Data = np.delete(Data,(1,2,3),axis=1)\n",
    "Y1 = np.array(Y1)\n",
    "Y_N = Y1/1000\n",
    "print(Data)\n",
    "print(Y_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(Data,Y_N, test_size =0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "robust_scaler1 = RobustScaler()\n",
    "robust_scaler1.fit(X_train1)\n",
    "x_robust_scaled1 = robust_scaler.transform(X_train1)\n",
    "print(x_robust_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_robust_scaled1 = x_robust_scaled1.reshape(len(x_robust_scaled1),1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3,n3= x_robust_scaled1.shape\n",
    "m4,n4= Y_train1.shape\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = mlp_model(n3,n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x_robust_scaled1, Y_train1, epochs=1000, validation_split=0.1, shuffle=True, verbose=1,  batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all1 = robust_scaler1.transform(Data)\n",
    "\n",
    "Ntot = model1.predict(x_all1)\n",
    "Ntot = Ntot*1000\n",
    "\n",
    "print(Ntot)\n",
    "print(Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = robust_scaler1.transform(X_test1)\n",
    "Ntot1 = model1.predict(x_test)\n",
    "score2= list(model1.evaluate(x_test,Y_test1, batch_size = 5, verbose=0))\n",
    "Ntot1 = Ntot1*1000\n",
    "Y_test_N = Y_test1*1000\n",
    "print(score2)\n",
    "print(Ntot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = np.append(Ntot,data1,axis=1)\n",
    "print(data3)\n",
    "Y_last = np.append(Y1,Y, axis=1)\n",
    "print(Y_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = np.append(Ntot1,data2, axis=1)\n",
    "print(data4)\n",
    "Y_last_test = np.append(Y_test_N,Y_test,axis=1)\n",
    "print(Y_last_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame(data3, columns=['Ntot_pred','d_em_pred','d_am_pred', 'Density_pred'])\n",
    "Real = pd.DataFrame(Y_last, columns=['Ntot','d_em','d_am', 'Density' ])\n",
    "Result2 = pd.concat([Pred, Real], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = pd.DataFrame(data4, columns=['Ntot_pred','d_em_pred','d_am_pred', 'Density_pred'])\n",
    "Real = pd.DataFrame(Y_last_test, columns=['Ntot','d_em','d_am','Density' ])\n",
    "Result3 = pd.concat([Pred, Real], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result2.to_csv('./Result_sintering2_all.csv',float_format='%.3f',sep=',', na_rep='NaN')\n",
    "Result3.to_csv('./Result_sintering2_test.csv',float_format='%.3f',sep=',', na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights(\"sintering_learning_all\"+\".h5\")\n",
    "model1.save('Sintering_model_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
